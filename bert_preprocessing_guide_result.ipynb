{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert_preprocessing_guide_result",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMxom69wLqdM4OxmZVhoEgN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/quocthang0507/tensorflow_text/blob/main/bert_preprocessing_guide_result.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FS56YE4G8ud"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DRPe9VYD0r-"
      },
      "source": [
        "!pip install -q -U tensorflow-text"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmemZCKhD6jo"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_text as text\n",
        "import functools"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJMTUXYZEBpV",
        "outputId": "0e963c46-e643-4d44-c942-a18e5ab54345"
      },
      "source": [
        "examples = {\n",
        "    \"text_a\": [\n",
        "      b\"Sponge bob Squarepants is an Avenger\",\n",
        "      b\"Marvel Avengers\"\n",
        "    ],\n",
        "    \"text_b\": [\n",
        "     b\"Barack Obama is the President.\",\n",
        "     b\"President is the highest office\"\n",
        "  ],\n",
        "}\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices(examples)\n",
        "next(iter(dataset))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text_a': <tf.Tensor: shape=(), dtype=string, numpy=b'Sponge bob Squarepants is an Avenger'>,\n",
              " 'text_b': <tf.Tensor: shape=(), dtype=string, numpy=b'Barack Obama is the President.'>}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXHl12oVG_o2"
      },
      "source": [
        "# Tokenizing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gkf1bte3EFJU"
      },
      "source": [
        "_VOCAB = [\n",
        "    # Special tokens\n",
        "    b\"[UNK]\", b\"[MASK]\", b\"[RANDOM]\", b\"[CLS]\", b\"[SEP]\",\n",
        "    # Suffixes\n",
        "    b\"##ack\", b\"##ama\", b\"##ger\", b\"##gers\", b\"##onge\", b\"##pants\",  b\"##uare\",\n",
        "    b\"##vel\", b\"##ven\", b\"an\", b\"A\", b\"Bar\", b\"Hates\", b\"Mar\", b\"Ob\",\n",
        "    b\"Patrick\", b\"President\", b\"Sp\", b\"Sq\", b\"bob\", b\"box\", b\"has\", b\"highest\",\n",
        "    b\"is\", b\"office\", b\"the\",\n",
        "]\n",
        "\n",
        "_START_TOKEN = _VOCAB.index(b\"[CLS]\")\n",
        "_END_TOKEN = _VOCAB.index(b\"[SEP]\")\n",
        "_MASK_TOKEN = _VOCAB.index(b\"[MASK]\")\n",
        "_RANDOM_TOKEN = _VOCAB.index(b\"[RANDOM]\")\n",
        "_UNK_TOKEN = _VOCAB.index(b\"[UNK]\")\n",
        "_MAX_SEQ_LEN = 8\n",
        "_MAX_PREDICTIONS_PER_BATCH = 5\n",
        " \n",
        "_VOCAB_SIZE = len(_VOCAB)\n",
        "\n",
        "lookup_table = tf.lookup.StaticVocabularyTable(\n",
        "    tf.lookup.KeyValueTensorInitializer(\n",
        "      keys=_VOCAB,\n",
        "      key_dtype=tf.string,\n",
        "      values=tf.range(\n",
        "          tf.size(_VOCAB, out_type=tf.int64), dtype=tf.int64),\n",
        "      value_dtype=tf.int64),\n",
        "      num_oov_buckets=1\n",
        ")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9viR6qXEExGx",
        "outputId": "365f05e5-825f-489b-eb45-61c318bcbf62"
      },
      "source": [
        "bert_tokenizer = text.BertTokenizer(lookup_table, token_out_type=tf.int64)\n",
        "segment_a = bert_tokenizer.tokenize(examples[\"text_a\"])\n",
        "segment_a"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[[22, 9], [24], [23, 11, 10], [28], [14], [15, 13, 7]], [[18, 12], [15, 13, 8]]]>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYDAMF-GE2y5",
        "outputId": "2760d79b-7439-4b14-d6c2-156907d1850f"
      },
      "source": [
        "segment_b = bert_tokenizer.tokenize(examples[\"text_b\"])\n",
        "segment_b"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[[16, 5], [19, 6], [28], [30], [21], [0]], [[21], [28], [30], [27], [29]]]>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFF6I4uCE8uX",
        "outputId": "9c8d5888-1e4f-4e61-87a9-69122d0f0bdb"
      },
      "source": [
        "segment_a = segment_a.merge_dims(-2, -1)\n",
        "segment_a"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[22, 9, 24, 23, 11, 10, 28, 14, 15, 13, 7], [18, 12, 15, 13, 8]]>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnMJEhBGE-da",
        "outputId": "813045ec-b495-4afa-bcac-c62f1c3c8cd1"
      },
      "source": [
        "segment_b = segment_b.merge_dims(-2, -1)\n",
        "segment_b"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[16, 5, 19, 6, 28, 30, 21, 0], [21, 28, 30, 27, 29]]>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQMJVkLJHDbu"
      },
      "source": [
        "# Content Trimming"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8aINc2cHI71",
        "outputId": "f90ae3e5-b929-4bfb-ddad-a7210b1d37e5"
      },
      "source": [
        "trimmer = text.RoundRobinTrimmer(max_seq_length=[_MAX_SEQ_LEN])\n",
        "trimmed = trimmer.trim([segment_a, segment_b])\n",
        "trimmed"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.RaggedTensor [[22, 9, 24, 23], [18, 12, 15, 13]]>,\n",
              " <tf.RaggedTensor [[16, 5, 19, 6], [21, 28, 30, 27]]>]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HtwXIR1HKb0"
      },
      "source": [
        "# Combining segments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eurm_UddEtJh",
        "outputId": "873e01f9-5cdd-470d-e118-872304d0f8e9"
      },
      "source": [
        "segments_combined, segments_ids = text.combine_segments(\n",
        "  [segment_a, segment_b],\n",
        "  start_of_sequence_id=_START_TOKEN, end_of_segment_id=_END_TOKEN)\n",
        "segments_combined, segments_ids"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.RaggedTensor [[3, 22, 9, 24, 23, 11, 10, 28, 14, 15, 13, 7, 4, 16, 5, 19, 6, 28, 30, 21, 0, 4], [3, 18, 12, 15, 13, 8, 4, 21, 28, 30, 27, 29, 4]]>,\n",
              " <tf.RaggedTensor [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]]>)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnGCKt0jHOHx"
      },
      "source": [
        "# Masked Language Model Task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYxO-h20HRTE"
      },
      "source": [
        "## Item Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJZyUu1qEqD_",
        "outputId": "439a5aa2-5221-4f4b-87cd-cdfc620d8fd6"
      },
      "source": [
        "random_selector = text.RandomItemSelector(\n",
        "    max_selections_per_batch=_MAX_PREDICTIONS_PER_BATCH,\n",
        "    selection_rate=0.2,\n",
        "    unselectable_ids=[_START_TOKEN, _END_TOKEN, _UNK_TOKEN]\n",
        ")\n",
        "selected = random_selector.get_selection_mask(\n",
        "    segments_combined, axis=1)\n",
        "selected"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[False, False, False, True, False, False, False, False, False, False, False, False, False, False, True, True, True, False, False, False, False, False], [False, False, False, False, False, False, False, False, True, True, False, False, False]]>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddh3NLVcHZUD"
      },
      "source": [
        "## Choosing the Masked Value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J85IWdW3GGrl",
        "outputId": "b820780a-4b8d-4177-8ccf-061508cb3106"
      },
      "source": [
        "input_ids = tf.ragged.constant([[19, 7, 21, 20, 9, 8], [13, 4, 16, 5], [15, 10, 12, 11, 6]])\n",
        "mask_values_chooser = text.MaskValuesChooser(_VOCAB_SIZE, _MASK_TOKEN, 0.8)\n",
        "mask_values_chooser.get_mask_values(input_ids)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[1, 7, 1, 1, 20, 1], [1, 1, 1, 10], [1, 16, 1, 1, 1]]>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GX1egq1wHcQ7"
      },
      "source": [
        "## Generating Inputs for Masked Language Model Task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eU4awwR0Gq9Y",
        "outputId": "e506e823-bace-400f-c8a4-c0d93590b989"
      },
      "source": [
        "masked_token_ids, masked_pos, masked_lm_ids = text.mask_language_model(\n",
        "  segments_combined,\n",
        "  item_selector=random_selector, mask_values_chooser=mask_values_chooser)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n",
            "Instructions for updating:\n",
            "`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPMyz_8nHe1P",
        "outputId": "36a3e9bd-eb4d-4a98-9c04-301872a4310d"
      },
      "source": [
        "masked_token_ids"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[3, 1, 9, 24, 23, 1, 10, 28, 14, 1, 13, 7, 4, 16, 5, 19, 6, 28, 30, 21, 0, 4], [3, 18, 16, 15, 13, 8, 4, 21, 28, 30, 1, 29, 4]]>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "570kzFVsHg44",
        "outputId": "7b8483bb-dc7c-4cd6-88ab-3ca007af6a7c"
      },
      "source": [
        "tf.gather(_VOCAB, masked_token_ids)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'[CLS]', b'[MASK]', b'##onge', b'bob', b'Sq', b'[MASK]', b'##pants', b'is', b'an', b'[MASK]', b'##ven', b'##ger', b'[SEP]', b'Bar', b'##ack', b'Ob', b'##ama', b'is', b'the', b'President', b'[UNK]', b'[SEP]'], [b'[CLS]', b'Mar', b'Bar', b'A', b'##ven', b'##gers', b'[SEP]', b'President', b'is', b'the', b'[MASK]', b'office', b'[SEP]']]>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_DlDDWUHoXm",
        "outputId": "a7a6018a-092d-4f0c-8c3a-c38fed35f68b"
      },
      "source": [
        "masked_pos\n",
        "masked_lm_ids"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[22, 11, 14, 15], [12, 27]]>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sx1BM2TpHkDW",
        "outputId": "8b17cfc7-bb3e-4643-9d15-f00cfcc65ac7"
      },
      "source": [
        "tf.gather(_VOCAB, masked_lm_ids)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'Sp', b'##uare', b'an', b'A'], [b'##vel', b'highest']]>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYKyy8S1Hvnu"
      },
      "source": [
        "# Padding Model Inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKyBLSbSH-hQ",
        "outputId": "0ce98957-7565-42af-fb60-b51b9c270606"
      },
      "source": [
        "\n",
        "# Prepare and pad combined segment inputs\n",
        "input_word_ids, input_mask = text.pad_model_inputs(\n",
        "  masked_token_ids, max_seq_length=_MAX_SEQ_LEN)\n",
        "input_type_ids, _ = text.pad_model_inputs(\n",
        "  masked_token_ids, max_seq_length=_MAX_SEQ_LEN)\n",
        "\n",
        "# Prepare and pad masking task inputs\n",
        "masked_lm_positions, masked_lm_weights = text.pad_model_inputs(\n",
        "  masked_token_ids, max_seq_length=_MAX_PREDICTIONS_PER_BATCH)\n",
        "masked_lm_ids, _ = text.pad_model_inputs(\n",
        "  masked_lm_ids, max_seq_length=_MAX_PREDICTIONS_PER_BATCH)\n",
        "\n",
        "model_inputs = {\n",
        "    \"input_word_ids\": input_word_ids,\n",
        "    \"input_mask\": input_mask,\n",
        "    \"input_type_ids\": input_type_ids,\n",
        "    \"masked_lm_ids\": masked_lm_ids,\n",
        "    \"masked_lm_positions\": masked_lm_positions,\n",
        "    \"masked_lm_weights\": masked_lm_weights,\n",
        "}\n",
        "model_inputs"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_mask': <tf.Tensor: shape=(2, 8), dtype=int64, numpy=\n",
              " array([[1, 1, 1, 1, 1, 1, 1, 1],\n",
              "        [1, 1, 1, 1, 1, 1, 1, 1]])>,\n",
              " 'input_type_ids': <tf.Tensor: shape=(2, 8), dtype=int64, numpy=\n",
              " array([[ 3,  1,  9, 24, 23,  1, 10, 28],\n",
              "        [ 3, 18, 16, 15, 13,  8,  4, 21]])>,\n",
              " 'input_word_ids': <tf.Tensor: shape=(2, 8), dtype=int64, numpy=\n",
              " array([[ 3,  1,  9, 24, 23,  1, 10, 28],\n",
              "        [ 3, 18, 16, 15, 13,  8,  4, 21]])>,\n",
              " 'masked_lm_ids': <tf.Tensor: shape=(2, 5), dtype=int64, numpy=\n",
              " array([[22, 11, 14, 15,  0],\n",
              "        [12, 27,  0,  0,  0]])>,\n",
              " 'masked_lm_positions': <tf.Tensor: shape=(2, 5), dtype=int64, numpy=\n",
              " array([[ 3,  1,  9, 24, 23],\n",
              "        [ 3, 18, 16, 15, 13]])>,\n",
              " 'masked_lm_weights': <tf.Tensor: shape=(2, 5), dtype=int64, numpy=\n",
              " array([[1, 1, 1, 1, 1],\n",
              "        [1, 1, 1, 1, 1]])>}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PKFHe84H_QF"
      },
      "source": [
        "# Review"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xznMPhwEEZuH"
      },
      "source": [
        "def bert_pretrain_preprocess(vocab_table, features):\n",
        "  # Input is a string Tensor of documents, shape [batch, 1].\n",
        "  text_a = features[\"text_a\"]\n",
        "  text_b = features[\"text_b\"]\n",
        "\n",
        "  # Tokenize segments to shape [num_sentences, (num_words)] each.\n",
        "  tokenizer = text.BertTokenizer(\n",
        "      vocab_table,\n",
        "      token_out_type=tf.int64)\n",
        "  segments = [tokenizer.tokenize(text).merge_dims(\n",
        "      1, -1) for text in (text_a, text_b)]\n",
        "\n",
        "  # Truncate inputs to a maximum length.\n",
        "  trimmer = text.RoundRobinTrimmer(max_seq_length=6)\n",
        "  trimmed_segments = trimmer.trim(segments)\n",
        "\n",
        "  # Combine segments, get segment ids and add special tokens.\n",
        "  segments_combined, segment_ids = text.combine_segments(\n",
        "      trimmed_segments,\n",
        "      start_of_sequence_id=_START_TOKEN,\n",
        "      end_of_segment_id=_END_TOKEN)\n",
        "\n",
        "  # Apply dynamic masking task.\n",
        "  masked_input_ids, masked_lm_positions, masked_lm_ids = (\n",
        "      text.mask_language_model(\n",
        "        segments_combined,\n",
        "        random_selector,\n",
        "        mask_values_chooser,\n",
        "      )\n",
        "  )\n",
        "  \n",
        "  # Prepare and pad combined segment inputs\n",
        "  input_word_ids, input_mask = text.pad_model_inputs(\n",
        "    masked_token_ids, max_seq_length=_MAX_SEQ_LEN)\n",
        "  input_type_ids, _ = text.pad_model_inputs(\n",
        "    masked_token_ids, max_seq_length=_MAX_SEQ_LEN)\n",
        "\n",
        "  # Prepare and pad masking task inputs\n",
        "  masked_lm_positions, masked_lm_weights = text.pad_model_inputs(\n",
        "    masked_token_ids, max_seq_length=_MAX_PREDICTIONS_PER_BATCH)\n",
        "  masked_lm_ids, _ = text.pad_model_inputs(\n",
        "    masked_lm_ids, max_seq_length=_MAX_PREDICTIONS_PER_BATCH)\n",
        "\n",
        "  model_inputs = {\n",
        "      \"input_word_ids\": input_word_ids,\n",
        "      \"input_mask\": input_mask,\n",
        "      \"input_type_ids\": input_type_ids,\n",
        "      \"masked_lm_ids\": masked_lm_ids,\n",
        "      \"masked_lm_positions\": masked_lm_positions,\n",
        "      \"masked_lm_weights\": masked_lm_weights,\n",
        "  }\n",
        "  return model_inputs"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPr3b9NyEeQF",
        "outputId": "c86e34f8-0c4e-433a-cc09-d9311f16a488"
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensors(examples)\n",
        "dataset = dataset.map(functools.partial(\n",
        "    bert_pretrain_preprocess, lookup_table))\n",
        "\n",
        "next(iter(dataset))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_mask': <tf.Tensor: shape=(2, 8), dtype=int64, numpy=\n",
              " array([[1, 1, 1, 1, 1, 1, 1, 1],\n",
              "        [1, 1, 1, 1, 1, 1, 1, 1]])>,\n",
              " 'input_type_ids': <tf.Tensor: shape=(2, 8), dtype=int64, numpy=\n",
              " array([[ 3,  1,  9, 24, 23,  1, 10, 28],\n",
              "        [ 3, 18, 16, 15, 13,  8,  4, 21]])>,\n",
              " 'input_word_ids': <tf.Tensor: shape=(2, 8), dtype=int64, numpy=\n",
              " array([[ 3,  1,  9, 24, 23,  1, 10, 28],\n",
              "        [ 3, 18, 16, 15, 13,  8,  4, 21]])>,\n",
              " 'masked_lm_ids': <tf.Tensor: shape=(2, 5), dtype=int64, numpy=\n",
              " array([[ 9, 16,  0,  0,  0],\n",
              "        [15, 28,  0,  0,  0]])>,\n",
              " 'masked_lm_positions': <tf.Tensor: shape=(2, 5), dtype=int64, numpy=\n",
              " array([[ 3,  1,  9, 24, 23],\n",
              "        [ 3, 18, 16, 15, 13]])>,\n",
              " 'masked_lm_weights': <tf.Tensor: shape=(2, 5), dtype=int64, numpy=\n",
              " array([[1, 1, 1, 1, 1],\n",
              "        [1, 1, 1, 1, 1]])>}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    }
  ]
}