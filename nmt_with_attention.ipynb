{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "nmt_with_attention.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Copyright 2019 The TensorFlow Authors.\n",
        "\n",
        "```\n",
        "@title Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "https://www.apache.org/licenses/LICENSE-2.0\n",
        "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n",
        "```"
      ],
      "metadata": {
        "id": "s_qNSzzyaCbD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dịch máy thần kinh với sự chú ý\n",
        "\n",
        "Sổ tay này huấn luyện một mô hình chuỗi đến chuỗi mô hình (seq2seq) cho ngôn ngữ Tây Ban Nha sang bản dịch tiếng Anh dựa trên hiệu quả [Effective Approaches to Attention-based Neural Machine Translation](https://arxiv.org/abs/1508.04025v5) . Đây là một ví dụ nâng cao giả định một số kiến ​​thức về:\n",
        "\n",
        "* Các mô hình seq2seq\n",
        "\n",
        "* Các nguyên tắc cơ bản của TensorFlow bên dưới lớp keras:\n",
        "\n",
        " * Làm việc trực tiếp với tensors\n",
        "\n",
        " * Viết tùy chỉnh các `keras.Model` và `keras.layers`\n",
        "\n",
        "Trong khi kiến trúc này có phần lỗi thời, nó vẫn là một dự án rất hữu ích cho công việc thông qua để có được một sự hiểu biết sâu sắc hơn về cơ chế chú ý (trước khi đi vào [Transformers](https://render.githubusercontent.com/view/transformer.ipynb)).\n",
        "\n",
        "Sau khi đào tạo mô hình trong máy tính xách tay này, bạn sẽ có thể nhập vào một câu tiếng Tây Ban Nha, chẳng hạn như \"*¿todavia estan en casa?*\", và gửi lại bản dịch tiếng Anh: \"*are you still at home?*\"\n",
        "\n",
        "Mô hình kết quả có thể xuất như là một mô hình `tf.saved_model`, vì vậy nó có thể được sử dụng trong các môi trường TensorFlow khác.\n",
        "\n",
        "Chất lượng bản dịch là hợp lý đối với một ví dụ về đồ chơi, nhưng đồ thì sự chú ý được tạo ra có lẽ thú vị hơn. Điều này cho thấy phần nào của câu đầu vào được mô hình chú ý trong khi dịch:\n",
        "\n",
        "![spanish-english](img/spanish-english.png)\n",
        "\n",
        "Lưu ý: Ví dụ này mất khoảng 10 phút để chạy trên một GPU P100 duy nhất."
      ],
      "metadata": {
        "id": "J0Qjg6vuaHNt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cài đặt"
      ],
      "metadata": {
        "id": "yAmSR1FaqKrl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!pip install tensorflow_text"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:42:56.383613Z",
          "iopub.status.busy": "2021-08-11T17:42:56.380054Z",
          "iopub.status.idle": "2021-08-11T17:43:19.159637Z",
          "shell.execute_reply": "2021-08-11T17:43:19.160015Z"
        },
        "id": "DGFTkuRvzWqc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import numpy as np\r\n",
        "\r\n",
        "import typing\r\n",
        "from typing import Any, Tuple\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow.keras.layers.experimental import preprocessing\r\n",
        "\r\n",
        "import tensorflow_text as tf_text\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import matplotlib.ticker as ticker"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:43:19.165570Z",
          "iopub.status.busy": "2021-08-11T17:43:19.164896Z",
          "iopub.status.idle": "2021-08-11T17:43:26.200420Z",
          "shell.execute_reply": "2021-08-11T17:43:26.199781Z"
        },
        "id": "tnxXKDjq3jEL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hướng dẫn này xây dựng một vài lớp từ đầu, hãy sử dụng biến này nếu bạn muốn chuyển đổi giữa triển khai tùy chỉnh và tích hợp."
      ],
      "metadata": {
        "id": "Vs8zge-RUdC2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "use_builtins = True"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:43:26.204899Z",
          "iopub.status.busy": "2021-08-11T17:43:26.204304Z",
          "iopub.status.idle": "2021-08-11T17:43:26.206501Z",
          "shell.execute_reply": "2021-08-11T17:43:26.206015Z"
        },
        "id": "KPJ9J7iPUchc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hướng dẫn này sử dụng rất nhiều API cấp thấp, nơi rất dễ làm sai hình dạng. Lớp này được sử dụng để kiểm tra các hình dạng trong suốt hướng dẫn.\n"
      ],
      "metadata": {
        "id": "l_yq8kvIqoqQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#@title Shape checker\r\n",
        "class ShapeChecker():\r\n",
        "  def __init__(self):\r\n",
        "    # Keep a cache of every axis-name seen\r\n",
        "    self.shapes = {}\r\n",
        "\r\n",
        "  def __call__(self, tensor, names, broadcast=False):\r\n",
        "    if not tf.executing_eagerly():\r\n",
        "      return\r\n",
        "\r\n",
        "    if isinstance(names, str):\r\n",
        "      names = (names,)\r\n",
        "\r\n",
        "    shape = tf.shape(tensor)\r\n",
        "    rank = tf.rank(tensor)\r\n",
        "\r\n",
        "    if rank != len(names):\r\n",
        "      raise ValueError(f'Rank mismatch:\\n'\r\n",
        "                       f'    found {rank}: {shape.numpy()}\\n'\r\n",
        "                       f'    expected {len(names)}: {names}\\n')\r\n",
        "\r\n",
        "    for i, name in enumerate(names):\r\n",
        "      if isinstance(name, int):\r\n",
        "        old_dim = name\r\n",
        "      else:\r\n",
        "        old_dim = self.shapes.get(name, None)\r\n",
        "      new_dim = shape[i]\r\n",
        "\r\n",
        "      if (broadcast and new_dim == 1):\r\n",
        "        continue\r\n",
        "\r\n",
        "      if old_dim is None:\r\n",
        "        # If the axis name is new, add its length to the cache.\r\n",
        "        self.shapes[name] = new_dim\r\n",
        "        continue\r\n",
        "\r\n",
        "      if new_dim != old_dim:\r\n",
        "        raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\r\n",
        "                         f\"    found: {new_dim}\\n\"\r\n",
        "                         f\"    expected: {old_dim}\\n\")"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:43:26.214112Z",
          "iopub.status.busy": "2021-08-11T17:43:26.213407Z",
          "iopub.status.idle": "2021-08-11T17:43:26.215484Z",
          "shell.execute_reply": "2021-08-11T17:43:26.215900Z"
        },
        "id": "KqFqKi4fqN9X"
<<<<<<< HEAD
      }
=======
      },
      "source": [
        "#@title Kiểm tra hình dạng\n",
        "class ShapeChecker():\n",
        "  def __init__(self):\n",
        "    # Keep a cache of every axis-name seen\n",
        "    self.shapes = {}\n",
        "\n",
        "  def __call__(self, tensor, names, broadcast=False):\n",
        "    if not tf.executing_eagerly():\n",
        "      return\n",
        "\n",
        "    if isinstance(names, str):\n",
        "      names = (names,)\n",
        "\n",
        "    shape = tf.shape(tensor)\n",
        "    rank = tf.rank(tensor)\n",
        "\n",
        "    if rank != len(names):\n",
        "      raise ValueError(f'Rank mismatch:\\n'\n",
        "                       f'    found {rank}: {shape.numpy()}\\n'\n",
        "                       f'    expected {len(names)}: {names}\\n')\n",
        "\n",
        "    for i, name in enumerate(names):\n",
        "      if isinstance(name, int):\n",
        "        old_dim = name\n",
        "      else:\n",
        "        old_dim = self.shapes.get(name, None)\n",
        "      new_dim = shape[i]\n",
        "\n",
        "      if (broadcast and new_dim == 1):\n",
        "        continue\n",
        "\n",
        "      if old_dim is None:\n",
        "        # If the axis name is new, add its length to the cache.\n",
        "        self.shapes[name] = new_dim\n",
        "        continue\n",
        "\n",
        "      if new_dim != old_dim:\n",
        "        raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
        "                         f\"    found: {new_dim}\\n\"\n",
        "                         f\"    expected: {old_dim}\\n\")"
      ],
      "execution_count": null,
      "outputs": []
>>>>>>> 5a73580559b41cf27f365796331b0b43bcebdca2
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dữ liệu\n",
        "\n",
        "Chúng tôi sẽ sử dụng một tập dữ liệu ngôn ngữ được cung cấp bởi http://www.manythings.org/anki/. Bộ dữ liệu này chứa các cặp dịch ngôn ngữ trong định dạng:\n",
        "\n",
        "```\n",
        "May I borrow this book?\t¿Puedo tomar prestado este libro?\n",
        "```\n",
        "\n",
        "Họ có nhiều ngôn ngữ khác nhau, nhưng chúng tôi sẽ sử dụng tập dữ liệu tiếng Anh-Tây Ban Nha."
      ],
      "metadata": {
        "id": "gjUROhJfH3ML"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tải xuống và chuẩn bị tập dữ liệu\n",
        "\n",
        "Để thuận tiện, chúng tôi đã lưu trữ bản sao của tập dữ liệu này trên Google Cloud, nhưng bạn cũng có thể tải xuống bản sao của riêng mình. Sau khi tải xuống tập dữ liệu, đây là các bước chúng tôi sẽ thực hiện để chuẩn bị dữ liệu:\n",
        "\n",
        "1. Thêm một token *start* và *end* cho mỗi câu.\n",
        "\n",
        "2. Làm sạch các câu bằng cách loại bỏ các ký tự đặc biệt.\n",
        "\n",
        "3. Tạo chỉ mục từ và chỉ mục từ đảo ngược (ánh xạ từ điển từ word → id và id → word).\n",
        "\n",
        "4. Đệm mỗi câu đến độ dài tối đa."
      ],
      "metadata": {
        "id": "wfodePkj3jEa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Download the file\r\n",
        "import pathlib\r\n",
        "\r\n",
        "path_to_zip = tf.keras.utils.get_file(\r\n",
        "    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\r\n",
        "    extract=True)\r\n",
        "\r\n",
        "path_to_file = pathlib.Path(path_to_zip).parent/'spa-eng/spa.txt'"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:43:26.220463Z",
          "iopub.status.busy": "2021-08-11T17:43:26.219906Z",
          "iopub.status.idle": "2021-08-11T17:43:26.500304Z",
          "shell.execute_reply": "2021-08-11T17:43:26.499744Z"
        },
        "id": "kRVATYOgJs1b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def load_data(path):\r\n",
        "  text = path.read_text(encoding='utf-8')\r\n",
        "\r\n",
        "  lines = text.splitlines()\r\n",
        "  pairs = [line.split('\\t') for line in lines]\r\n",
        "\r\n",
        "  inp = [inp for targ, inp in pairs]\r\n",
        "  targ = [targ for targ, inp in pairs]\r\n",
        "\r\n",
        "  return targ, inp"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:43:26.505898Z",
          "iopub.status.busy": "2021-08-11T17:43:26.505275Z",
          "iopub.status.idle": "2021-08-11T17:43:26.507748Z",
          "shell.execute_reply": "2021-08-11T17:43:26.507149Z"
        },
        "id": "OHn4Dct23jEm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "targ, inp = load_data(path_to_file)\r\n",
        "print(inp[-1])"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:43:26.511945Z",
          "iopub.status.busy": "2021-08-11T17:43:26.511302Z",
          "iopub.status.idle": "2021-08-11T17:43:26.933001Z",
          "shell.execute_reply": "2021-08-11T17:43:26.933561Z"
        },
        "id": "cTbSbBz55QtF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print(targ[-1])"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:43:26.938112Z",
          "iopub.status.busy": "2021-08-11T17:43:26.937499Z",
          "iopub.status.idle": "2021-08-11T17:43:26.939705Z",
          "shell.execute_reply": "2021-08-11T17:43:26.940064Z"
        },
        "id": "lH_dPY8TRp3c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tạo tập dữ liệu tf.data\n",
        "\n",
        "Từ những mảng của chuỗi bạn có thể tạo một `tf.data.Dataset` các chuỗi xáo trộn và cho vào lô một cách hiệu quả:"
      ],
      "metadata": {
        "id": "rgCLkfv5uO3d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "BUFFER_SIZE = len(inp)\r\n",
        "BATCH_SIZE = 64\r\n",
        "\r\n",
        "dataset = tf.data.Dataset.from_tensor_slices((inp, targ)).shuffle(BUFFER_SIZE)\r\n",
        "dataset = dataset.batch(BATCH_SIZE)"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:43:26.999916Z",
          "iopub.status.busy": "2021-08-11T17:43:26.963450Z",
          "iopub.status.idle": "2021-08-11T17:43:28.746775Z",
          "shell.execute_reply": "2021-08-11T17:43:28.746257Z"
        },
        "id": "TqHsArVZ3jFS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "for example_input_batch, example_target_batch in dataset.take(1):\r\n",
        "  print(example_input_batch[:5])\r\n",
        "  print()\r\n",
        "  print(example_target_batch[:5])\r\n",
        "  break"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:43:28.751580Z",
          "iopub.status.busy": "2021-08-11T17:43:28.750915Z",
          "iopub.status.idle": "2021-08-11T17:43:28.970419Z",
          "shell.execute_reply": "2021-08-11T17:43:28.970890Z"
        },
        "id": "qc6-NK1GtWQt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tiền xử lý văn bản\n",
        "\n",
        "Một trong những mục tiêu của hướng dẫn này là xây dựng một mô hình có thể được xuất ra dưới dạng một `tf.saved_model`. Để thực hiện mô hình đã xuất hữu ích, nó nên lấy các đầu vào `tf.string`, và trả về các đầu ra `tf.string`: Tất cả quá trình xử lý văn bản diễn ra bên trong mô hình."
      ],
      "metadata": {
        "id": "zCoxLcuN3bwv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chuẩn hoá\n",
        "\n",
        "Mô hình đang xử lý văn bản đa ngôn ngữ với vốn từ vựng hạn chế. Vì vậy, việc chuẩn hóa văn bản đầu vào sẽ rất quan trọng.\n",
        "\n",
        "Bước đầu tiên là chuẩn hóa Unicode để tách các ký tự có dấu và thay thế các ký tự tương thích bằng các ký tự tương đương ASCII của chúng.\n",
        "\n",
        "Các `tensroflow_text` gói chứa một hoạt động bình thường hóa unicode:"
      ],
      "metadata": {
        "id": "EOQ5n55X4uDB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "example_text = tf.constant('¿Todavía está en casa?')\r\n",
        "\r\n",
        "print(example_text.numpy())\r\n",
        "print(tf_text.normalize_utf8(example_text, 'NFKD').numpy())"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:43:28.977796Z",
          "iopub.status.busy": "2021-08-11T17:43:28.977180Z",
          "iopub.status.idle": "2021-08-11T17:43:28.979633Z",
          "shell.execute_reply": "2021-08-11T17:43:28.979994Z"
        },
        "id": "mD0e-DWGQ2Vo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chuẩn hóa Unicode sẽ là bước đầu tiên trong hàm chuẩn hóa văn bản:"
      ],
      "metadata": {
        "id": "6hTllEjK6RSo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def tf_lower_and_split_punct(text):\r\n",
        "  # Split accecented characters.\r\n",
        "  text = tf_text.normalize_utf8(text, 'NFKD')\r\n",
        "  text = tf.strings.lower(text)\r\n",
        "  # Keep space, a to z, and select punctuation.\r\n",
        "  text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '')\r\n",
        "  # Add spaces around punctuation.\r\n",
        "  text = tf.strings.regex_replace(text, '[.?!,¿]', r' \\0 ')\r\n",
        "  # Strip whitespace.\r\n",
        "  text = tf.strings.strip(text)\r\n",
        "\r\n",
        "  text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\r\n",
        "  return text"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:43:28.985273Z",
          "iopub.status.busy": "2021-08-11T17:43:28.984710Z",
          "iopub.status.idle": "2021-08-11T17:43:28.986453Z",
          "shell.execute_reply": "2021-08-11T17:43:28.986841Z"
        },
        "id": "chTF5N885F0P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print(example_text.numpy().decode())\r\n",
        "print(tf_lower_and_split_punct(example_text).numpy().decode())"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:43:28.990899Z",
          "iopub.status.busy": "2021-08-11T17:43:28.990283Z",
          "iopub.status.idle": "2021-08-11T17:43:28.993573Z",
          "shell.execute_reply": "2021-08-11T17:43:28.993927Z"
        },
        "id": "UREvDg3sEKYa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Véctơ hoá văn bản\n",
        "\n",
        "Chức năng chuẩn hoá này sẽ được gói trong một lớp `preprocessing.TextVectorization` lớp mà sẽ xử lý việc khai thác vốn từ vựng và chuyển đổi văn bản đầu vào thành các chuối token."
      ],
      "metadata": {
        "id": "4q-sKsSI7xRZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "max_vocab_size = 5000\r\n",
        "\r\n",
        "input_text_processor = preprocessing.TextVectorization(\r\n",
        "    standardize=tf_lower_and_split_punct,\r\n",
        "    max_tokens=max_vocab_size)"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:43:28.997809Z",
          "iopub.status.busy": "2021-08-11T17:43:28.997248Z",
          "iopub.status.idle": "2021-08-11T17:43:29.014320Z",
          "shell.execute_reply": "2021-08-11T17:43:29.014681Z"
        },
        "id": "eAY9k49G3jE_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Các lớp `TextVectorization` và các lớp `experimental.preprocessing` khác có một phương thức `adapt`. Phương thức này lần đọc một epoch của dữ liệu huấn luyện, và hoạt động rất nhiều giống `Model.fix`. Phương thức `adapt` này khởi tạo các lớp dựa trên dữ liệu. Ở đây nó xác định từ vựng:"
      ],
      "metadata": {
        "id": "7kbC6ODP8IK_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "input_text_processor.adapt(inp)\r\n",
        "\r\n",
        "# Here are the first 10 words from the vocabulary:\r\n",
        "input_text_processor.get_vocabulary()[:10]"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:43:29.061289Z",
          "iopub.status.busy": "2021-08-11T17:43:29.051057Z",
          "iopub.status.idle": "2021-08-11T17:43:58.975423Z",
          "shell.execute_reply": "2021-08-11T17:43:58.975808Z"
        },
        "id": "bmsI1Yql8FYe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Đó là lớp `TextVectorization` tiếng Tây Ban Nha, bây giờ xây dựng và `.adapt()` tiếng Anh cái này:"
      ],
      "metadata": {
        "id": "9kGjIFjX8_Wp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "output_text_processor = preprocessing.TextVectorization(\r\n",
        "    standardize=tf_lower_and_split_punct,\r\n",
        "    max_tokens=max_vocab_size)\r\n",
        "\r\n",
        "output_text_processor.adapt(targ)\r\n",
        "output_text_processor.get_vocabulary()[:10]"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:43:59.026512Z",
          "iopub.status.busy": "2021-08-11T17:43:59.004677Z",
          "iopub.status.idle": "2021-08-11T17:44:28.494369Z",
          "shell.execute_reply": "2021-08-11T17:44:28.494836Z"
        },
        "id": "jlC4xuZnKLBS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Giờ đây, các lớp này có thể chuyển đổi một lô các chuỗi thành một lô các token ID:"
      ],
      "metadata": {
        "id": "BWQqlP_s9eIv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "example_tokens = input_text_processor(example_input_batch)\n",
        "example_tokens[:3, :10]"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:44:28.499510Z",
          "iopub.status.busy": "2021-08-11T17:44:28.498897Z",
          "iopub.status.idle": "2021-08-11T17:44:28.508511Z",
          "shell.execute_reply": "2021-08-11T17:44:28.507988Z"
        },
        "id": "9KZxj8IrNZ9S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Phương thức `get_vocabulary` có thể được sử dụng để chuyển đổi các token ID trở lại thành văn bản:"
      ],
      "metadata": {
        "id": "AA9rUn9G9n78"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "input_vocab = np.array(input_text_processor.get_vocabulary())\r\n",
        "tokens = input_vocab[example_tokens[0].numpy()]\r\n",
        "' '.join(tokens)"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:44:28.512770Z",
          "iopub.status.busy": "2021-08-11T17:44:28.512158Z",
          "iopub.status.idle": "2021-08-11T17:44:28.521278Z",
          "shell.execute_reply": "2021-08-11T17:44:28.521619Z"
        },
        "id": "98g9rcxGQY0I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Các token ID được trả về không có đệm. Điều này có thể dễ dàng để trở thành mặt nạ:"
      ],
      "metadata": {
        "id": "Ot0aCL9t-Ghi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plt.subplot(1, 2, 1)\r\n",
        "plt.pcolormesh(example_tokens)\r\n",
        "plt.title('Token IDs')\r\n",
        "\r\n",
        "plt.subplot(1, 2, 2)\r\n",
        "plt.pcolormesh(example_tokens != 0)\r\n",
        "plt.title('Mask')"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:44:28.526338Z",
          "iopub.status.busy": "2021-08-11T17:44:28.523867Z",
          "iopub.status.idle": "2021-08-11T17:44:28.711591Z",
          "shell.execute_reply": "2021-08-11T17:44:28.711067Z"
        },
        "id": "_jx4Or_eFRSz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mô hình bộ mã hoá/giải mã\n",
        "\n",
        "Sơ đồ sau đây cho thấy tổng quan về mô hình. Tại mỗi bước thời gian, đầu ra của bộ giải mã được kết hợp với tổng trọng số trên đầu vào được mã hóa, để dự đoán từ tiếp theo. Sơ đồ và công thức từ [bài báo của Lương](https://arxiv.org/abs/1508.04025v5).\n",
        "\n",
        "![attention_mechanism](img/attention_mechanism.jpg)\n"
      ],
      "metadata": {
        "id": "TNfHIF71ulLu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trước khi đi sâu vào nó, hãy xác định một vài hằng số cho mô hình:"
      ],
      "metadata": {
        "id": "gzQWx2saImMV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "embedding_dim = 256\r\n",
        "units = 1024"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:44:28.715885Z",
          "iopub.status.busy": "2021-08-11T17:44:28.715133Z",
          "iopub.status.idle": "2021-08-11T17:44:28.717669Z",
          "shell.execute_reply": "2021-08-11T17:44:28.717189Z"
        },
        "id": "_a9uNz3-IrF-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bộ mã hoá\n",
        "\n",
        "Bắt đầu bằng cách xây dựng bộ mã hóa, phần màu xanh lam của sơ đồ ở trên.\n",
        "\n",
        "Bộ mã hóa:\n",
        "\n",
        "1. Lấy một danh sách các token ID (từ `input_text_processor`).\n",
        "\n",
        "2. Tra cứu một véctơ nhúng cho mỗi token (Sử dụng một `layers.Embedding`).\n",
        "\n",
        "3. Xử lý các nhúng thành một chuỗi mới (Sử dụng một `layers.GRU`).\n",
        "\n",
        "4. Trả về:\n",
        "    * Chuỗi đã xử lý. Điều này sẽ được chuyển đến phía chú ý.\n",
        "    * Trạng thái bên trong. Điều này sẽ được sử dụng để khởi tạo bộ giải mã"
      ],
      "metadata": {
        "id": "blNgVbLSzpsr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "class Encoder(tf.keras.layers.Layer):\r\n",
        "  def __init__(self, input_vocab_size, embedding_dim, enc_units):\r\n",
        "    super(Encoder, self).__init__()\r\n",
        "    self.enc_units = enc_units\r\n",
        "    self.input_vocab_size = input_vocab_size\r\n",
        "\r\n",
        "    # The embedding layer converts tokens to vectors\r\n",
        "    self.embedding = tf.keras.layers.Embedding(self.input_vocab_size,\r\n",
        "                                               embedding_dim)\r\n",
        "\r\n",
        "    # The GRU RNN layer processes those vectors sequentially.\r\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\r\n",
        "                                   # Return the sequence and state\r\n",
        "                                   return_sequences=True,\r\n",
        "                                   return_state=True,\r\n",
        "                                   recurrent_initializer='glorot_uniform')\r\n",
        "\r\n",
        "  def call(self, tokens, state=None):\r\n",
        "    shape_checker = ShapeChecker()\r\n",
        "    shape_checker(tokens, ('batch', 's'))\r\n",
        "\r\n",
        "    # 2. The embedding layer looks up the embedding for each token.\r\n",
        "    vectors = self.embedding(tokens)\r\n",
        "    shape_checker(vectors, ('batch', 's', 'embed_dim'))\r\n",
        "\r\n",
        "    # 3. The GRU processes the embedding sequence.\r\n",
        "    #    output shape: (batch, s, enc_units)\r\n",
        "    #    state shape: (batch, enc_units)\r\n",
        "    output, state = self.gru(vectors, initial_state=state)\r\n",
        "    shape_checker(output, ('batch', 's', 'enc_units'))\r\n",
        "    shape_checker(state, ('batch', 'enc_units'))\r\n",
        "\r\n",
        "    # 4. Returns the new sequence and its state.\r\n",
        "    return output, state"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:44:28.724579Z",
          "iopub.status.busy": "2021-08-11T17:44:28.723758Z",
          "iopub.status.idle": "2021-08-11T17:44:28.725897Z",
          "shell.execute_reply": "2021-08-11T17:44:28.725488Z"
        },
        "id": "nZ2rI24i3jFg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Đây là cách nó phù hợp với nhau cho đến nay:"
      ],
      "metadata": {
        "id": "D3SKkaQeGn-Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Convert the input text to tokens.\r\n",
        "example_tokens = input_text_processor(example_input_batch)\r\n",
        "\r\n",
        "# Encode the input sequence.\r\n",
        "encoder = Encoder(input_text_processor.vocabulary_size(),\r\n",
        "                  embedding_dim, units)\r\n",
        "example_enc_output, example_enc_state = encoder(example_tokens)\r\n",
        "\r\n",
        "print(f'Input batch, shape (batch): {example_input_batch.shape}')\r\n",
        "print(f'Input batch tokens, shape (batch, s): {example_tokens.shape}')\r\n",
        "print(f'Encoder output, shape (batch, s, units): {example_enc_output.shape}')\r\n",
        "print(f'Encoder state, shape (batch, units): {example_enc_state.shape}')"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:44:28.731604Z",
          "iopub.status.busy": "2021-08-11T17:44:28.730647Z",
          "iopub.status.idle": "2021-08-11T17:44:29.390583Z",
          "shell.execute_reply": "2021-08-11T17:44:29.391108Z"
        },
        "id": "60gSVh05Jl6l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bộ mã hóa trả về trạng thái bên trong của nó để trạng thái của nó có thể được sử dụng để khởi tạo bộ giải mã.\n",
        "\n",
        "RNN cũng thường trả về trạng thái của nó để nó có thể xử lý một chuỗi qua nhiều cuộc gọi. Bạn sẽ thấy nhiều hơn về việc xây dựng bộ giải mã."
      ],
      "metadata": {
        "id": "2RIPHh4O9ixB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Phía chú ý\n",
        "\n",
        "Bộ giải mã sử dụng sự chú ý để tập trung có chọn lọc vào các phần của chuỗi đầu vào. Sự chú ý lấy một chuỗi các véctơ làm đầu vào cho mỗi ví dụ và trả về một véctơ \"chú ý\" cho mỗi ví dụ. Lớp chú ý này cũng tương tự như một `layers.GlobalAveragePoling1D` nhưng lớp chú ý thực hiện một trung bình *có trọng số*.\n",
        "\n",
        "Hãy xem cách này hoạt động như thế nào:\n",
        "\n",
        "1. Phương trình đầu tiên:\n",
        "\n",
<<<<<<< HEAD
        "$$\n",
        "\\boldsymbol{c}_t = \\sum_{s}^{}\\alpha_{ts}\\boldsymbol{\\overline{h}}_s \\hspace{6cm} \\textrm{[Context vector]} \\hspace{1em}(2)\n",
        "$$"
      ],
      "metadata": {
        "id": "45xM_Gl1MgXY"
      }
=======
        "![equation_1](img/attention_equation_1.jpg)\n",
        "\n",
        "```\n",
        "$$ \\alpha_{ts}=\\frac{\\mathrm{exp}\\left (\\mathrm{score} \\left (\\boldsymbol{h}_t,\\boldsymbol{\\overline{h}}_s \\right )\\right )}{\\sum_{s'=1}^{S}\\mathrm{exp}\\left (\\mathrm{score\\left (\\boldsymbol{h}_t,\\boldsymbol{\\overline{h}}_{s'} \\right )} \\right )} \\qquad \\textrm{[Attention weights]}\\qquad(1) $$\n",
        "```\n",
        "\n",
        "2. Phương trình thứ hai:\n",
        "\n",
        "![equation_2](img/attention_equation_2.jpg)\n",
        "\n",
        "```\n",
        "\\boldsymbol{c}_t = \\sum_{s}^{}\\alpha_{ts}\\boldsymbol{\\overline{h}}_s \\qquad \\textrm{[Context vector]} \\qquad(2)\n",
        "```"
      ]
>>>>>>> 5a73580559b41cf27f365796331b0b43bcebdca2
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trong đó:\n",
        "\n",
        "* $s$ là chỉ số bộ mã hoá.\n",
        "* $t$ là chỉ số bộ giải mã.\n",
        "* $\\alpha_{ts}$ là các trọng số chú ý.\n",
        "* $h_s$ là chuỗi của đầu ra bộ mã hoá được tham gia (sự chú ý \"key\" và \"value\" trong thuật ngữ transformer).\n",
        "* $h_t$ là trạng thái bộ giải mã tham gia vào chuỗi (sự chú ý \"query\" có trong thuật ngữ transformer).\n",
        "* $c_t$ là véctơ ngữ cảnh kết quả.\n",
        "* $a_t$ là đầu ra cuối cùng kết hợp \"context\" và \"query\".\n",
        "\n",
        "Các phương trình:\n",
        "\n",
        "1. Tính toán các trọng số chú ý, $\\alpha_{ts}$, như một softmax ngang qua chuỗi đầu ra của bộ mã hoá.\n",
        "2. Tính toán véctơ ngữ cảnh như tổng các đầu ra bộ mã hoá có trọng số.\n"
      ],
      "metadata": {
        "id": "NX2JsKzzzgZ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cuối cùng là hàm $\\textrm{score}$. Công việc của nó là tính toán điểm-logit vô hướng cho mỗi cặp khóa-truy vấn. Có hai cách tiếp cận phổ biến:\n",
        "\n",
        "$$\n",
        "\\mathrm{score}\\left (\\boldsymbol{h}_t,\\boldsymbol{\\overline{h}}_s\\right )=\\left\\{\\begin{matrix}\n",
        "\\boldsymbol{{h}^{\\top}_{t}W\\overline{h}_s}\\qquad\\textrm{[Luong's multiplicative style]}\\\\ \n",
        "\\boldsymbol{\\upsilon }^{\\top}_a\\mathrm{tanh}\\left (\\boldsymbol{W_1h_t}+\\boldsymbol{W_2\\overline{h}_s} \\right )\\qquad\\textrm{[Bahdanau's additive style]}\n",
        "\\end{matrix}\\right. (4)\n",
        "$$\n",
        "\n",
        "Hướng dẫn này sử dụng [Bahdanau's additive attention](https://arxiv.org/pdf/1409.0473.pdf). TensorFlow bao gồm các triển khai của cả hai `layers.Attention` và\n",
        "`layers.AdditiveAttention`. Lớp bên dưới xử lý các ma trận trọng số trong một cặp của các lớp `layers.Dense`, và gọi triển khai tích hợp."
      ],
      "metadata": {
        "id": "fNA5GeHHPsGL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\r\n",
        "  def __init__(self, units):\r\n",
        "    super().__init__()\r\n",
        "    # For Eqn. (4), the  Bahdanau attention\r\n",
        "    self.W1 = tf.keras.layers.Dense(units, use_bias=False)\r\n",
        "    self.W2 = tf.keras.layers.Dense(units, use_bias=False)\r\n",
        "\r\n",
        "    self.attention = tf.keras.layers.AdditiveAttention()\r\n",
        "\r\n",
        "  def call(self, query, value, mask):\r\n",
        "    shape_checker = ShapeChecker()\r\n",
        "    shape_checker(query, ('batch', 't', 'query_units'))\r\n",
        "    shape_checker(value, ('batch', 's', 'value_units'))\r\n",
        "    shape_checker(mask, ('batch', 's'))\r\n",
        "\r\n",
        "    # From Eqn. (4), `W1@ht`.\r\n",
        "    w1_query = self.W1(query)\r\n",
        "    shape_checker(w1_query, ('batch', 't', 'attn_units'))\r\n",
        "\r\n",
        "    # From Eqn. (4), `W2@hs`.\r\n",
        "    w2_key = self.W2(value)\r\n",
        "    shape_checker(w2_key, ('batch', 's', 'attn_units'))\r\n",
        "\r\n",
        "    query_mask = tf.ones(tf.shape(query)[:-1], dtype=bool)\r\n",
        "    value_mask = mask\r\n",
        "\r\n",
        "    context_vector, attention_weights = self.attention(\r\n",
        "        inputs = [w1_query, value, w2_key],\r\n",
        "        mask=[query_mask, value_mask],\r\n",
        "        return_attention_scores = True,\r\n",
        "    )\r\n",
        "    shape_checker(context_vector, ('batch', 't', 'value_units'))\r\n",
        "    shape_checker(attention_weights, ('batch', 't', 's'))\r\n",
        "\r\n",
        "    return context_vector, attention_weights"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:44:29.400543Z",
          "iopub.status.busy": "2021-08-11T17:44:29.399924Z",
          "iopub.status.idle": "2021-08-11T17:44:29.401471Z",
          "shell.execute_reply": "2021-08-11T17:44:29.401905Z"
        },
        "id": "momiE59lXo6U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Kiểm tra lớp Chú ý\n",
        "\n",
        "Tạo một lớp `BahdanauAttention`:"
      ],
      "metadata": {
        "id": "Cf13LubPGjDO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "attention_layer = BahdanauAttention(units)"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:44:29.409420Z",
          "iopub.status.busy": "2021-08-11T17:44:29.408757Z",
          "iopub.status.idle": "2021-08-11T17:44:29.410707Z",
          "shell.execute_reply": "2021-08-11T17:44:29.410266Z"
        },
        "id": "t4QMlOp8Gidh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lớp này có 3 đầu vào:\n",
        "\n",
        "* `query`: Nó sẽ được tạo ra bởi bộ giải mã sau này..\n",
        "* `value`: Nó sẽ là đầu ra của bộ mã hoá.\n",
        "* `mask`: Ngoại trừ đệm, `example_tokens != 0`"
      ],
      "metadata": {
        "id": "snA1uL9AI-JE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "(example_tokens != 0).shape"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:44:29.415176Z",
          "iopub.status.busy": "2021-08-11T17:44:29.414560Z",
          "iopub.status.idle": "2021-08-11T17:44:29.416833Z",
          "shell.execute_reply": "2021-08-11T17:44:29.417237Z"
        },
        "id": "DYSHqmORgVFo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Việc triển khai véctơ hóa của lớp chú ý cho phép bạn chuyển một lô chuỗi các vectơ truy vấn và một lô chuỗi các vectơ giá trị. Kết quả là:\n",
        "\n",
        "1. Một lô của các chuỗi của các véctơ kết quả với kích thước của các truy vấn.\n",
        "\n",
        "2. Một lô các bản đồ chú ý, với kích thước `(query_length, value_length)`."
      ],
      "metadata": {
        "id": "g2bmvT25pXnr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Later, the decoder will generate this attention query\r\n",
        "example_attention_query = tf.random.normal(shape=[len(example_tokens), 2, 10])\r\n",
        "\r\n",
        "# Attend to the encoded tokens\r\n",
        "\r\n",
        "context_vector, attention_weights = attention_layer(\r\n",
        "    query=example_attention_query,\r\n",
        "    value=example_enc_output,\r\n",
        "    mask=(example_tokens != 0))\r\n",
        "\r\n",
        "print(f'Attention result shape: (batch_size, query_seq_length, units):           {context_vector.shape}')\r\n",
        "print(f'Attention weights shape: (batch_size, query_seq_length, value_seq_length): {attention_weights.shape}')"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:44:29.422016Z",
          "iopub.status.busy": "2021-08-11T17:44:29.421456Z",
          "iopub.status.idle": "2021-08-11T17:44:29.793343Z",
          "shell.execute_reply": "2021-08-11T17:44:29.793736Z"
        },
        "id": "7y7hjPkNMmHh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Các trọng số chú ý nên tổng hợp thành 1.0 cho mỗi chuỗi.\n",
        "\n",
        "Dưới đây là các trọng số chú ý trên chuỗi tại `t=0`:"
      ],
      "metadata": {
        "id": "AagyXMH-Jhqt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plt.subplot(1, 2, 1)\r\n",
        "plt.pcolormesh(attention_weights[:, 0, :])\r\n",
        "plt.title('Attention weights')\r\n",
        "\r\n",
        "plt.subplot(1, 2, 2)\r\n",
        "plt.pcolormesh(example_tokens != 0)\r\n",
        "plt.title('Mask')\r\n"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:44:29.816767Z",
          "iopub.status.busy": "2021-08-11T17:44:29.816096Z",
          "iopub.status.idle": "2021-08-11T17:44:29.988965Z",
          "shell.execute_reply": "2021-08-11T17:44:29.988407Z"
        },
        "id": "Rqr8XGsAJlf6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bởi vì sự khởi tạo ngẫu nhiên nhỏ các trọng số chú ý tất cả gần `1/(sequence_length)`. Nếu bạn phóng to trên các trọng số cho một chuỗi duy nhất, bạn có thể thấy rằng có một số sự thay đổi *nhỏ* rằng mô hình có thể học hỏi để mở rộng và khai thác."
      ],
      "metadata": {
        "id": "6Eil-C_NN1rp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "attention_weights.shape"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:44:29.993874Z",
          "iopub.status.busy": "2021-08-11T17:44:29.993227Z",
          "iopub.status.idle": "2021-08-11T17:44:29.995681Z",
          "shell.execute_reply": "2021-08-11T17:44:29.996078Z"
        },
        "id": "ZuzrCdmYlTcJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "attention_slice = attention_weights[0, 0].numpy()\r\n",
        "attention_slice = attention_slice[attention_slice != 0]"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:44:30.000283Z",
          "iopub.status.busy": "2021-08-11T17:44:29.999681Z",
          "iopub.status.idle": "2021-08-11T17:44:30.002001Z",
          "shell.execute_reply": "2021-08-11T17:44:30.002365Z"
        },
        "id": "qIMwC-f-ZC8N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#@title\r\n",
        "plt.suptitle('Attention weights for one sequence')\r\n",
        "\r\n",
        "plt.figure(figsize=(12, 6))\r\n",
        "a1 = plt.subplot(1, 2, 1)\r\n",
        "plt.bar(range(len(attention_slice)), attention_slice)\r\n",
        "# freeze the xlim\r\n",
        "plt.xlim(plt.xlim())\r\n",
        "plt.xlabel('Attention weights')\r\n",
        "\r\n",
        "a2 = plt.subplot(1, 2, 2)\r\n",
        "plt.bar(range(len(attention_slice)), attention_slice)\r\n",
        "plt.xlabel('Attention weights, zoomed')\r\n",
        "\r\n",
        "# zoom in\r\n",
        "top = max(a1.get_ylim())\r\n",
        "zoom = 0.85*top\r\n",
        "a2.set_ylim([0.90*top, top])\r\n",
        "a1.plot(a1.get_xlim(), [zoom, zoom], color='k')"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:44:30.044170Z",
          "iopub.status.busy": "2021-08-11T17:44:30.030025Z",
          "iopub.status.idle": "2021-08-11T17:44:30.249843Z",
          "shell.execute_reply": "2021-08-11T17:44:30.250205Z"
        },
        "id": "ysWDPO6hOS8X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bộ giải mã\n",
        "\n",
        "Công việc của bộ giải mã là tạo ra các dự đoán cho token đầu ra tiếp theo.\n",
        "\n",
        "1. Bộ giải mã nhận được đầu ra bộ mã hóa hoàn chỉnh.\n",
        "\n",
        "2. Nó sử dụng RNN để theo dõi những gì nó đã tạo ra cho đến nay.\n",
        "\n",
        "3. Nó sử dụng đầu ra RNN làm truy vấn để truy vấn sự chú ý qua đầu ra của bộ mã hóa, tạo ra vectơ ngữ cảnh.\n",
        "\n",
        "4. Nó kết hợp đầu ra RNN và vectơ ngữ cảnh bằng cách sử dụng Công thức 3 (bên dưới) để tạo ra \"vectơ chú ý\".\n",
        "\n",
        "5. Nó tạo ra các dự đoán logit cho token tiếp theo dựa trên \"vectơ chú ý\".\n",
        "\n",
        "$$\n",
        "\\boldsymbol{\\alpha}_t=f(\\boldsymbol{c}_t,\\boldsymbol{h}=\\mathrm{tanh}\\left (\\boldsymbol{W_c[c_t;h_t]} \\right )\\qquad\\textrm{[Attention vector]}\n",
        "$$\n",
        "\n",
        "Đây là lớp `Decoder` và khởi tạo của nó. Trình khởi tạo tạo tất cả các lớp cần thiết."
      ],
      "metadata": {
        "id": "aQ638eHN4iCK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "class Decoder(tf.keras.layers.Layer):\r\n",
        "  def __init__(self, output_vocab_size, embedding_dim, dec_units):\r\n",
        "    super(Decoder, self).__init__()\r\n",
        "    self.dec_units = dec_units\r\n",
        "    self.output_vocab_size = output_vocab_size\r\n",
        "    self.embedding_dim = embedding_dim\r\n",
        "\r\n",
        "    # For Step 1. The embedding layer convets token IDs to vectors\r\n",
        "    self.embedding = tf.keras.layers.Embedding(self.output_vocab_size,\r\n",
        "                                               embedding_dim)\r\n",
        "\r\n",
        "    # For Step 2. The RNN keeps track of what's been generated so far.\r\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\r\n",
        "                                   return_sequences=True,\r\n",
        "                                   return_state=True,\r\n",
        "                                   recurrent_initializer='glorot_uniform')\r\n",
        "\r\n",
        "    # For step 3. The RNN output will be the query for the attention layer.\r\n",
        "    self.attention = BahdanauAttention(self.dec_units)\r\n",
        "\r\n",
        "    # For step 4. Eqn. (3): converting `ct` to `at`\r\n",
        "    self.Wc = tf.keras.layers.Dense(dec_units, activation=tf.math.tanh,\r\n",
        "                                    use_bias=False)\r\n",
        "\r\n",
        "    # For step 5. This fully connected layer produces the logits for each\r\n",
        "    # output token.\r\n",
        "    self.fc = tf.keras.layers.Dense(self.output_vocab_size)"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:44:30.257402Z",
          "iopub.status.busy": "2021-08-11T17:44:30.256606Z",
          "iopub.status.idle": "2021-08-11T17:44:30.258609Z",
          "shell.execute_reply": "2021-08-11T17:44:30.258983Z"
        },
        "id": "erYvHIgAl8kh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Phương thức `call` cho lớp này lấy và trả về nhiều tensors. Tổ chức chúng thành các lớp chứa đơn giản:"
      ],
      "metadata": {
        "id": "eUTfYHmfmwKH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "class DecoderInput(typing.NamedTuple):\r\n",
        "  new_tokens: Any\r\n",
        "  enc_output: Any\r\n",
        "  mask: Any\r\n",
        "\r\n",
        "class DecoderOutput(typing.NamedTuple):\r\n",
        "  logits: Any\r\n",
        "  attention_weights: Any"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:44:30.263998Z",
          "iopub.status.busy": "2021-08-11T17:44:30.263428Z",
          "iopub.status.idle": "2021-08-11T17:44:30.265270Z",
          "shell.execute_reply": "2021-08-11T17:44:30.265647Z"
        },
        "id": "7WfSIb2sArRT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Đây là việc triển khai phương thức `call`:"
      ],
      "metadata": {
        "id": "NChkl2KrnV2y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def call(self,\r\n",
        "         inputs: DecoderInput,\r\n",
        "         state=None) -> Tuple[DecoderOutput, tf.Tensor]:\r\n",
        "  shape_checker = ShapeChecker()\r\n",
        "  shape_checker(inputs.new_tokens, ('batch', 't'))\r\n",
        "  shape_checker(inputs.enc_output, ('batch', 's', 'enc_units'))\r\n",
        "  shape_checker(inputs.mask, ('batch', 's'))\r\n",
        "\r\n",
        "  if state is not None:\r\n",
        "    shape_checker(state, ('batch', 'dec_units'))\r\n",
        "\r\n",
        "  # Step 1. Lookup the embeddings\r\n",
        "  vectors = self.embedding(inputs.new_tokens)\r\n",
        "  shape_checker(vectors, ('batch', 't', 'embedding_dim'))\r\n",
        "\r\n",
        "  # Step 2. Process one step with the RNN\r\n",
        "  rnn_output, state = self.gru(vectors, initial_state=state)\r\n",
        "\r\n",
        "  shape_checker(rnn_output, ('batch', 't', 'dec_units'))\r\n",
        "  shape_checker(state, ('batch', 'dec_units'))\r\n",
        "\r\n",
        "  # Step 3. Use the RNN output as the query for the attention over the\r\n",
        "  # encoder output.\r\n",
        "  context_vector, attention_weights = self.attention(\r\n",
        "      query=rnn_output, value=inputs.enc_output, mask=inputs.mask)\r\n",
        "  shape_checker(context_vector, ('batch', 't', 'dec_units'))\r\n",
        "  shape_checker(attention_weights, ('batch', 't', 's'))\r\n",
        "\r\n",
        "  # Step 4. Eqn. (3): Join the context_vector and rnn_output\r\n",
        "  #     [ct; ht] shape: (batch t, value_units + query_units)\r\n",
        "  context_and_rnn_output = tf.concat([context_vector, rnn_output], axis=-1)\r\n",
        "\r\n",
        "  # Step 4. Eqn. (3): `at = tanh(Wc@[ct; ht])`\r\n",
        "  attention_vector = self.Wc(context_and_rnn_output)\r\n",
        "  shape_checker(attention_vector, ('batch', 't', 'dec_units'))\r\n",
        "\r\n",
        "  # Step 5. Generate logit predictions:\r\n",
        "  logits = self.fc(attention_vector)\r\n",
        "  shape_checker(logits, ('batch', 't', 'output_vocab_size'))\r\n",
        "\r\n",
        "  return DecoderOutput(logits, attention_weights), state"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:44:30.274454Z",
          "iopub.status.busy": "2021-08-11T17:44:30.273736Z",
          "iopub.status.idle": "2021-08-11T17:44:30.275603Z",
          "shell.execute_reply": "2021-08-11T17:44:30.275946Z"
        },
        "id": "PJOi5btHAPNK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "Decoder.call = call"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:44:30.279854Z",
          "iopub.status.busy": "2021-08-11T17:44:30.279219Z",
          "iopub.status.idle": "2021-08-11T17:44:30.281615Z",
          "shell.execute_reply": "2021-08-11T17:44:30.281169Z"
        },
        "id": "Ay_mTMPfnb2a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Các **bộ mã hóa** xử lý chuỗi đầu vào đầy đủ của nó với một cuộc gọi duy nhất đến RNN của nó. Thực hiện này của các **bộ giải mã** *có thể* làm điều đó cũng cho hiệu quả huấn luyện. Nhưng hướng dẫn này sẽ chạy bộ giải mã trong một vòng lặp vì một số lý do:\n",
        "\n",
        "* Linh hoạt: Viết vòng lặp cho phép bạn kiểm soát trực tiếp quy trình huấn luyện.\n",
        "* Rõ ràng: Có thể làm mặt nạ thủ thuật và sử dụng `layers.RNN`, hoặc API `tfa.seq2seq` để đóng gói tất cả thành một cuộc gọi duy nhất. Nhưng viết nó ra dưới dạng một vòng lặp có thể rõ ràng hơn.\n",
        "\n",
        "    * Vòng lặp huấn luyện miễn phí được trình bày trong hướng dẫn [sinh văn bản](https://www.tensorflow.org/text/tutorials/text_generation).\n"
      ],
      "metadata": {
        "id": "arTOBklcFTiC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bây giờ hãy thử sử dụng bộ giải mã này."
      ],
      "metadata": {
        "id": "E1-mLAcUEXpK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "decoder = Decoder(output_text_processor.vocabulary_size(),\r\n",
        "                  embedding_dim, units)"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:44:30.292378Z",
          "iopub.status.busy": "2021-08-11T17:44:30.291669Z",
          "iopub.status.idle": "2021-08-11T17:44:30.294045Z",
          "shell.execute_reply": "2021-08-11T17:44:30.293607Z"
        },
        "id": "4ZUMbYXIEVeA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bộ giải mã có 4 đầu vào.\n",
        "\n",
        "* `new_tokens` - Các token cuối cùng được tạo. Khởi tạo các bộ giải mã với token `\"[START]\"`.\n",
        "\n",
        "* `enc_output` - được tạo ra bởi `Encoder`.\n",
        "\n",
        "* `mask` - Một tensor boolean chỉ ra nơi `tokens != 0`\n",
        "\n",
        "* `state` - Các đầu ra `state` trước từ các bộ giải mã (trạng thái nội bộ của RNN của bộ giải mã). Vượt qua `None` để khởi tạo-không cho nó. Bài gốc khởi tạo nó từ trạng thái RNN cuối cùng của bộ mã hóa."
      ],
      "metadata": {
        "id": "UPnaw583CpnY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Convert the target sequence, and collect the \"[START]\" tokens\r\n",
        "example_output_tokens = output_text_processor(example_target_batch)\r\n",
        "\r\n",
        "start_index = output_text_processor.get_vocabulary().index('[START]')\r\n",
        "first_token = tf.constant([[start_index]] * example_output_tokens.shape[0])"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:44:30.298977Z",
          "iopub.status.busy": "2021-08-11T17:44:30.298366Z",
          "iopub.status.idle": "2021-08-11T17:44:30.305985Z",
          "shell.execute_reply": "2021-08-11T17:44:30.305575Z"
        },
        "id": "4u6eJBU4GL40"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Run the decoder\r\n",
        "dec_result, dec_state = decoder(\r\n",
        "    inputs = DecoderInput(new_tokens=first_token,\r\n",
        "                          enc_output=example_enc_output,\r\n",
        "                          mask=(example_tokens != 0)),\r\n",
        "    state = example_enc_state\r\n",
        ")\r\n",
        "\r\n",
        "print(f'logits shape: (batch_size, t, output_vocab_size) {dec_result.logits.shape}')\r\n",
        "print(f'state shape: (batch_size, dec_units) {dec_state.shape}')"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:44:30.311069Z",
          "iopub.status.busy": "2021-08-11T17:44:30.309981Z",
          "iopub.status.idle": "2021-08-11T17:44:30.345340Z",
          "shell.execute_reply": "2021-08-11T17:44:30.344884Z"
        },
        "id": "E5hqvbR5FUCD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lấy mẫu token theo các logit:"
      ],
      "metadata": {
        "id": "vEZvXZRVPHd6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "sampled_token = tf.random.categorical(dec_result.logits[:, 0, :], num_samples=1)"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:44:30.350269Z",
          "iopub.status.busy": "2021-08-11T17:44:30.349689Z",
          "iopub.status.idle": "2021-08-11T17:44:30.351907Z",
          "shell.execute_reply": "2021-08-11T17:44:30.352262Z"
        },
        "id": "P5UY8wko3jFp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Giải mã token dưới dạng từ đầu tiên của đầu ra:"
      ],
      "metadata": {
        "id": "-xTpX44VkzrY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "vocab = np.array(output_text_processor.get_vocabulary())\n",
        "first_word = vocab[sampled_token.numpy()]\n",
        "first_word[:5]"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:44:30.356448Z",
          "iopub.status.busy": "2021-08-11T17:44:30.355849Z",
          "iopub.status.idle": "2021-08-11T17:44:30.365729Z",
          "shell.execute_reply": "2021-08-11T17:44:30.365291Z"
        },
        "id": "lKXTLYu4IV7I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bây giờ, hãy sử dụng bộ giải mã để tạo bộ logit thứ hai.\n",
        "\n",
        "* Chuyển cùng `enc_output` và `mask`, những điều này không thay đổi.\n",
        "\n",
        "* Chuyển qua mẫu token như `new_tokens`.\n",
        "\n",
        "* Chuyển `decoder_state` bộ giải mã trả về lần cuối cùng, vì vậy RNN tiếp tục với một bộ nhớ về nơi nó rời khỏi thời gian qua."
      ],
      "metadata": {
        "id": "LUQV6AXoQR7z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "dec_result, dec_state = decoder(\n",
        "    DecoderInput(sampled_token,\n",
        "                 example_enc_output,\n",
        "                 mask=(example_tokens != 0)),\n",
        "    state=dec_state)"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:44:30.369861Z",
          "iopub.status.busy": "2021-08-11T17:44:30.369066Z",
          "iopub.status.idle": "2021-08-11T17:44:30.388671Z",
          "shell.execute_reply": "2021-08-11T17:44:30.389052Z"
        },
        "id": "pX1VF9XDJTOM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "sampled_token = tf.random.categorical(dec_result.logits[:, 0, :], num_samples=1)\n",
        "first_word = vocab[sampled_token.numpy()]\n",
        "first_word[:5]"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:44:30.393644Z",
          "iopub.status.busy": "2021-08-11T17:44:30.393008Z",
          "iopub.status.idle": "2021-08-11T17:44:30.397374Z",
          "shell.execute_reply": "2021-08-11T17:44:30.396884Z"
        },
        "id": "H1rs0XL7Y2aS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Huấn luyện\n",
        "\n",
        "Bây giờ bạn đã có tất cả các thành phần của mô hình, đã đến lúc bắt đầu huấn luyện mô hình. Có thể bạn sẽ cần:\n",
        "\n",
        "* Một hàm mất mát và trình tối ưu hóa để thực hiện việc tối ưu hóa.\n",
        "\n",
        "* Hàm bước huấn luyện xác định cách cập nhật mô hình cho từng lô đầu vào/mục tiêu.\n",
        "\n",
        "* Một vòng lặp huấn luyện để thúc đẩy quá trình huấn luyện và lưu các điểm kiểm tra."
      ],
      "metadata": {
        "id": "B6xyru86m914"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Định nghĩa hàm mất mát"
      ],
      "metadata": {
        "id": "_ch_71VbIRfK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "class MaskedLoss(tf.keras.losses.Loss):\n",
        "  def __init__(self):\n",
        "    self.name = 'masked_loss'\n",
        "    self.loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True, reduction='none')\n",
        "\n",
        "  def __call__(self, y_true, y_pred):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(y_true, ('batch', 't'))\n",
        "    shape_checker(y_pred, ('batch', 't', 'logits'))\n",
        "\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    loss = self.loss(y_true, y_pred)\n",
        "    shape_checker(loss, ('batch', 't'))\n",
        "\n",
        "    # Mask off the losses on padding.\n",
        "    mask = tf.cast(y_true != 0, tf.float32)\n",
        "    shape_checker(mask, ('batch', 't'))\n",
        "    loss *= mask\n",
        "\n",
        "    # Return the total.\n",
        "    return tf.reduce_sum(loss)"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:44:30.404083Z",
          "iopub.status.busy": "2021-08-11T17:44:30.403304Z",
          "iopub.status.idle": "2021-08-11T17:44:30.405355Z",
          "shell.execute_reply": "2021-08-11T17:44:30.405696Z"
        },
        "id": "WmTHr5iV3jFr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Triển khai bước huấn luyện"
      ],
      "metadata": {
        "id": "M5AgEBh2S404"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bắt đầu với một lớp mô hình, quá trình huấn luyện sẽ được triển khai như phương thức `train_step` trên mô hình này. Xem [Tuỳ chỉnh phù hợp](https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit) để biết chi tiết.\n",
        "\n",
        "Ở đây phương thức `train_step` là một gói bọc quanh triển khai `_train_step` sẽ đến sau. Gói bao bọc này bao gồm một công tắc để bật và tắt biên dịch `tf.function`, để cho gỡ lỗi dễ dàng hơn."
      ],
      "metadata": {
        "id": "r_G20Te1XSmJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "class TrainTranslator(tf.keras.Model):\n",
        "  def __init__(self, embedding_dim, units,\n",
        "               input_text_processor,\n",
        "               output_text_processor, \n",
        "               use_tf_function=True):\n",
        "    super().__init__()\n",
        "    # Build the encoder and decoder\n",
        "    encoder = Encoder(input_text_processor.vocabulary_size(),\n",
        "                      embedding_dim, units)\n",
        "    decoder = Decoder(output_text_processor.vocabulary_size(),\n",
        "                      embedding_dim, units)\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.input_text_processor = input_text_processor\n",
        "    self.output_text_processor = output_text_processor\n",
        "    self.use_tf_function = use_tf_function\n",
        "    self.shape_checker = ShapeChecker()\n",
        "\n",
        "  def train_step(self, inputs):\n",
        "    self.shape_checker = ShapeChecker()\n",
        "    if self.use_tf_function:\n",
        "      return self._tf_train_step(inputs)\n",
        "    else:\n",
        "      return self._train_step(inputs)"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:44:30.412291Z",
          "iopub.status.busy": "2021-08-11T17:44:30.411650Z",
          "iopub.status.idle": "2021-08-11T17:44:30.414006Z",
          "shell.execute_reply": "2021-08-11T17:44:30.413568Z"
        },
        "id": "WWIyuy71TkJT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nhìn chung triển khai cho phương thức `Model.train_step` là như sau:\n",
        "\n",
        "1. Nhận một lô `input_text`, `target_text` từ `tf.data.Dataset`.\n",
        "\n",
        "2. Chuyển đổi các đầu vào văn bản thô đó thành token-nhúng và mặt nạ.\n",
        "\n",
        "3. Chạy bộ mã hóa trên `input_tokens` để có được `encoder_output` và `encoder_state`.\n",
        "4. Khởi tạo trạng thái bộ giải mã và mất mát.\n",
        "\n",
        "5. Vòng lặp qua `target_tokens`:\n",
        "\n",
        "    a. Chạy bộ giải mã từng bước một.\n",
        "\n",
        "    b. Tính toán sự mất mát cho mỗi bước.\n",
        "\n",
        "    c. Tích lũy mất mát trung bình.\n",
        "\n",
        "6. Tính độ dốc của mất mát và sử dụng tối ưu hóa để áp dụng bản cập nhật trên trainable_variables` của mô hình.\n",
        "\n",
        "Phương thức `_preprocess` được bổ sung dưới đây, thực hiện bước #1 và #2:"
      ],
      "metadata": {
        "id": "-i0i1x6jwsLm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def _preprocess(self, input_text, target_text):\n",
        "  self.shape_checker(input_text, ('batch',))\n",
        "  self.shape_checker(target_text, ('batch',))\n",
        "\n",
        "  # Convert the text to token IDs\n",
        "  input_tokens = self.input_text_processor(input_text)\n",
        "  target_tokens = self.output_text_processor(target_text)\n",
        "  self.shape_checker(input_tokens, ('batch', 's'))\n",
        "  self.shape_checker(target_tokens, ('batch', 't'))\n",
        "\n",
        "  # Convert IDs to masks.\n",
        "  input_mask = input_tokens != 0\n",
        "  self.shape_checker(input_mask, ('batch', 's'))\n",
        "\n",
        "  target_mask = target_tokens != 0\n",
        "  self.shape_checker(target_mask, ('batch', 't'))\n",
        "\n",
        "  return input_tokens, input_mask, target_tokens, target_mask"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:44:30.419648Z",
          "iopub.status.busy": "2021-08-11T17:44:30.419017Z",
          "iopub.status.idle": "2021-08-11T17:44:30.421341Z",
          "shell.execute_reply": "2021-08-11T17:44:30.420904Z"
        },
        "id": "ZlYE68wzXoA8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "TrainTranslator._preprocess = _preprocess"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:44:30.425238Z",
          "iopub.status.busy": "2021-08-11T17:44:30.424599Z",
          "iopub.status.idle": "2021-08-11T17:44:30.426990Z",
          "shell.execute_reply": "2021-08-11T17:44:30.426487Z"
        },
        "id": "lHy6hzStrgjQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Phương thức `_train_step` được thêm vào bên dưới, xử lý các bước còn lại ngoại trừ thực sự chạy bộ giải mã:"
      ],
      "metadata": {
        "id": "d3kvbcArc2y-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def _train_step(self, inputs):\n",
        "  input_text, target_text = inputs  \n",
        "\n",
        "  (input_tokens, input_mask,\n",
        "   target_tokens, target_mask) = self._preprocess(input_text, target_text)\n",
        "\n",
        "  max_target_length = tf.shape(target_tokens)[1]\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    # Encode the input\n",
        "    enc_output, enc_state = self.encoder(input_tokens)\n",
        "    self.shape_checker(enc_output, ('batch', 's', 'enc_units'))\n",
        "    self.shape_checker(enc_state, ('batch', 'enc_units'))\n",
        "\n",
        "    # Initialize the decoder's state to the encoder's final state.\n",
        "    # This only works if the encoder and decoder have the same number of\n",
        "    # units.\n",
        "    dec_state = enc_state\n",
        "    loss = tf.constant(0.0)\n",
        "\n",
        "    for t in tf.range(max_target_length-1):\n",
        "      # Pass in two tokens from the target sequence:\n",
        "      # 1. The current input to the decoder.\n",
        "      # 2. The target the target for the decoder's next prediction.\n",
        "      new_tokens = target_tokens[:, t:t+2]\n",
        "      step_loss, dec_state = self._loop_step(new_tokens, input_mask,\n",
        "                                             enc_output, dec_state)\n",
        "      loss = loss + step_loss\n",
        "\n",
        "    # Average the loss over all non padding tokens.\n",
        "    average_loss = loss / tf.reduce_sum(tf.cast(target_mask, tf.float32))\n",
        "\n",
        "  # Apply an optimization step\n",
        "  variables = self.trainable_variables \n",
        "  gradients = tape.gradient(average_loss, variables)\n",
        "  self.optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  # Return a dict mapping metric names to current value\n",
        "  return {'batch_loss': average_loss}"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:44:30.434502Z",
          "iopub.status.busy": "2021-08-11T17:44:30.433813Z",
          "iopub.status.idle": "2021-08-11T17:44:30.436143Z",
          "shell.execute_reply": "2021-08-11T17:44:30.435716Z"
        },
        "id": "Qs_gsISsYPpY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "TrainTranslator._train_step = _train_step"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:44:30.440071Z",
          "iopub.status.busy": "2021-08-11T17:44:30.439449Z",
          "iopub.status.idle": "2021-08-11T17:44:30.441815Z",
          "shell.execute_reply": "2021-08-11T17:44:30.441386Z"
        },
        "id": "KGwWHIxLrjGR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Phương thức `_loop_step` được bổ sung dưới đây, thực hiện các bộ giải mã và tính toán sự mất mát gia tăng và trạng thái giải mã mới (`dec_state`)."
      ],
      "metadata": {
        "id": "F7g40o-mXyt5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def _loop_step(self, new_tokens, input_mask, enc_output, dec_state):\n",
        "  input_token, target_token = new_tokens[:, 0:1], new_tokens[:, 1:2]\n",
        "\n",
        "  # Run the decoder one step.\n",
        "  decoder_input = DecoderInput(new_tokens=input_token,\n",
        "                               enc_output=enc_output,\n",
        "                               mask=input_mask)\n",
        "\n",
        "  dec_result, dec_state = self.decoder(decoder_input, state=dec_state)\n",
        "  self.shape_checker(dec_result.logits, ('batch', 't1', 'logits'))\n",
        "  self.shape_checker(dec_result.attention_weights, ('batch', 't1', 's'))\n",
        "  self.shape_checker(dec_state, ('batch', 'dec_units'))\n",
        "\n",
        "  # `self.loss` returns the total for non-padded tokens\n",
        "  y = target_token\n",
        "  y_pred = dec_result.logits\n",
        "  step_loss = self.loss(y, y_pred)\n",
        "\n",
        "  return step_loss, dec_state"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:44:30.447875Z",
          "iopub.status.busy": "2021-08-11T17:44:30.447104Z",
          "iopub.status.idle": "2021-08-11T17:44:30.449470Z",
          "shell.execute_reply": "2021-08-11T17:44:30.448905Z"
        },
        "id": "9VrzgwztXzYJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "TrainTranslator._loop_step = _loop_step"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:44:30.453412Z",
          "iopub.status.busy": "2021-08-11T17:44:30.452798Z",
          "iopub.status.idle": "2021-08-11T17:44:30.455139Z",
          "shell.execute_reply": "2021-08-11T17:44:30.454684Z"
        },
        "id": "xj3I7VULrk1R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Kiểm tra bước huấn luyện\n",
        "\n",
        "Xây dựng một `TrainTranslator`, và cấu hình nó cho huấn luyện bằng cách sử dụng phương thức `Model.compile`:"
      ],
      "metadata": {
        "id": "WACCHvKWBQ9C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "translator = TrainTranslator(\n",
        "    embedding_dim, units,\n",
        "    input_text_processor=input_text_processor,\n",
        "    output_text_processor=output_text_processor,\n",
        "    use_tf_function=False)\n",
        "\n",
        "# Configure the loss and optimizer\n",
        "translator.compile(\n",
        "    optimizer=tf.optimizers.Adam(),\n",
        "    loss=MaskedLoss(),\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:44:30.460253Z",
          "iopub.status.busy": "2021-08-11T17:44:30.459653Z",
          "iopub.status.idle": "2021-08-11T17:44:30.477708Z",
          "shell.execute_reply": "2021-08-11T17:44:30.477243Z"
        },
        "id": "OA6bCske8TXm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kiểm tra train_step`. Đối với một mô hình văn bản như thế này, sự mất mát sẽ bắt đầu gần:"
      ],
      "metadata": {
        "id": "6y5OnZDsB3sB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "np.log(output_text_processor.vocabulary_size())"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:44:30.482748Z",
          "iopub.status.busy": "2021-08-11T17:44:30.482021Z",
          "iopub.status.idle": "2021-08-11T17:44:30.485142Z",
          "shell.execute_reply": "2021-08-11T17:44:30.484689Z"
        },
        "id": "zHe-OudqCFGK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%%time\n",
        "for n in range(10):\n",
        "  print(translator.train_step([example_input_batch, example_target_batch]))\n",
        "print()"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:44:30.489884Z",
          "iopub.status.busy": "2021-08-11T17:44:30.489278Z",
          "iopub.status.idle": "2021-08-11T17:44:35.861884Z",
          "shell.execute_reply": "2021-08-11T17:44:35.861409Z"
        },
        "id": "VwMU9cFEfjha"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trong khi nó dễ dàng hơn để gỡ lỗi mà không có một `tf.function`, nó làm tăng hiệu suất. Vì vậy, bây giờ mà phương thức `_train_step` đang làm việc, hãy thử các `tf.function` -wrapped `_tf_train_step`, để tối đa hóa hiệu suất trong khi huấn luyện:"
      ],
      "metadata": {
        "id": "A-xqtsMbCUp2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "@tf.function(input_signature=[[tf.TensorSpec(dtype=tf.string, shape=[None]),\n",
        "                               tf.TensorSpec(dtype=tf.string, shape=[None])]])\n",
        "def _tf_train_step(self, inputs):\n",
        "  return self._train_step(inputs)"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:44:35.867061Z",
          "iopub.status.busy": "2021-08-11T17:44:35.866383Z",
          "iopub.status.idle": "2021-08-11T17:44:35.869060Z",
          "shell.execute_reply": "2021-08-11T17:44:35.868613Z"
        },
        "id": "UFUsTKQx0jaH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "TrainTranslator._tf_train_step = _tf_train_step"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:44:35.873052Z",
          "iopub.status.busy": "2021-08-11T17:44:35.872474Z",
          "iopub.status.idle": "2021-08-11T17:44:35.874994Z",
          "shell.execute_reply": "2021-08-11T17:44:35.874530Z"
        },
        "id": "2-bgU59jrztQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "translator.use_tf_function = True"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:44:35.878945Z",
          "iopub.status.busy": "2021-08-11T17:44:35.878393Z",
          "iopub.status.idle": "2021-08-11T17:44:35.880560Z",
          "shell.execute_reply": "2021-08-11T17:44:35.880905Z"
        },
        "id": "KC8bRv_Gr3H9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cuộc gọi đầu tiên sẽ chậm, vì nó theo dõi hàm."
      ],
      "metadata": {
        "id": "EKMYNF_sIFb9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "translator.train_step([example_input_batch, example_target_batch])"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:44:35.885984Z",
          "iopub.status.busy": "2021-08-11T17:44:35.884507Z",
          "iopub.status.idle": "2021-08-11T17:44:39.805968Z",
          "shell.execute_reply": "2021-08-11T17:44:39.805458Z"
        },
        "id": "pLQZsX2dp1QK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nhưng sau đó nó thường nhanh hơn gấp 2-3 lần so với phương thức `train_step`:"
      ],
      "metadata": {
        "id": "W3t2Hg7UISYi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%%time\n",
        "for n in range(10):\n",
        "  print(translator.train_step([example_input_batch, example_target_batch]))\n",
        "print()"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:44:39.812140Z",
          "iopub.status.busy": "2021-08-11T17:44:39.811128Z",
          "iopub.status.idle": "2021-08-11T17:44:41.792138Z",
          "shell.execute_reply": "2021-08-11T17:44:41.792520Z"
        },
        "id": "UzXXMwjXCqqh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Một bài kiểm tra tốt đối với một mô hình mới là để thấy rằng nó có thể quá khớp một lô đầu vào duy nhất. Hãy thử nó, mất mát sẽ nhanh chóng về 0:"
      ],
      "metadata": {
        "id": "OIvigTqaEcu1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "losses = []\n",
        "for n in range(100):\n",
        "  print('.', end='')\n",
        "  logs = translator.train_step([example_input_batch, example_target_batch])\n",
        "  losses.append(logs['batch_loss'].numpy())\n",
        "\n",
        "print()\n",
        "plt.plot(losses)"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:44:41.798357Z",
          "iopub.status.busy": "2021-08-11T17:44:41.797450Z",
          "iopub.status.idle": "2021-08-11T17:45:02.059677Z",
          "shell.execute_reply": "2021-08-11T17:45:02.060103Z"
        },
        "id": "U-dIWMIBqK7b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bây giờ bạn đã tự tin rằng bước huấn luyện đang hoạt động, hãy tạo một bản sao mới của mô hình để huấn luyện từ đầu:"
      ],
      "metadata": {
        "id": "aI02XFjoEt1k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "train_translator = TrainTranslator(\n",
        "    embedding_dim, units,\n",
        "    input_text_processor=input_text_processor,\n",
        "    output_text_processor=output_text_processor)\n",
        "\n",
        "# Configure the loss and optimizer\n",
        "train_translator.compile(\n",
        "    optimizer=tf.optimizers.Adam(),\n",
        "    loss=MaskedLoss(),\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:45:02.065670Z",
          "iopub.status.busy": "2021-08-11T17:45:02.065091Z",
          "iopub.status.idle": "2021-08-11T17:45:02.080367Z",
          "shell.execute_reply": "2021-08-11T17:45:02.079904Z"
        },
        "id": "Emgfgh4tAmJt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Huấn luyện mô hình\n",
        "\n",
        "Trong khi không có gì sai với viết vòng lặp huấn luyện tùy chỉnh riêng của bạn, thực hiện phương thức `Model.train_step`, như trong phần trước, cho phép bạn chạy `Model.fit` và tránh viết lại tất cả những mã nồi *boiler-plate*. \n",
        "\n",
        "Hướng dẫn này chỉ huấn luyện cho một vài epoch, vì vậy sử dụng một `callbacks.Callback` để thu thập lịch sử của mất mát lô cho việc vẽ đồ thị:"
      ],
      "metadata": {
        "id": "hpObfY22IddU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "class BatchLogs(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, key):\n",
        "    self.key = key\n",
        "    self.logs = []\n",
        "\n",
        "  def on_train_batch_end(self, n, logs):\n",
        "    self.logs.append(logs[self.key])\n",
        "\n",
        "batch_loss = BatchLogs('batch_loss')"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:45:02.085439Z",
          "iopub.status.busy": "2021-08-11T17:45:02.084840Z",
          "iopub.status.idle": "2021-08-11T17:45:02.086750Z",
          "shell.execute_reply": "2021-08-11T17:45:02.087129Z"
        },
        "id": "J7m4mtnj80sq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "train_translator.fit(dataset, epochs=3,\n",
        "                     callbacks=[batch_loss])"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T17:45:02.090967Z",
          "iopub.status.busy": "2021-08-11T17:45:02.089520Z",
          "iopub.status.idle": "2021-08-11T18:04:19.404866Z",
          "shell.execute_reply": "2021-08-11T18:04:19.405349Z"
        },
        "id": "BQd_esVVoSf3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plt.plot(batch_loss.logs)\n",
        "plt.ylim([0, 3])\n",
        "plt.xlabel('Batch #')\n",
        "plt.ylabel('CE/token')"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T18:04:19.424894Z",
          "iopub.status.busy": "2021-08-11T18:04:19.424275Z",
          "iopub.status.idle": "2021-08-11T18:04:19.528223Z",
          "shell.execute_reply": "2021-08-11T18:04:19.527700Z"
        },
        "id": "38rLdlmtQHCm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Các bước nhảy có thể nhìn thấy trong đồ thị nằm ở ranh giới epoch."
      ],
      "metadata": {
        "id": "w0S_O_RzHmfe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dịch\n",
        "\n",
        "Bây giờ mà các mô hình được huấn luyện, gọi một hàm để thực hiện dịch đầy đủ `text => text`.\n",
        "\n",
        "Đối với điều này nhu cầu mô hình để đảo ngược ánh xạ `text => token IDs` được cung cấp bởi các `output_text_processor`. Nó cũng cần biết các ID cho các token đặc biệt. Tất cả điều này được thực hiện trong phương thức khởi tạo cho lớp mới. Việc triển khai phương pháp dịch thực tế sẽ tuân theo.\n",
        "\n",
        "Nhìn chung, điều này tương tự như vòng lặp huấn luyện, ngoại trừ đầu vào cho bộ giải mã ở mỗi bước thời gian là một mẫu từ dự đoán cuối cùng của bộ giải mã."
      ],
      "metadata": {
        "id": "mU3Ce8M6I3rz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "class Translator(tf.Module):\n",
        "\n",
        "  def __init__(self, encoder, decoder, input_text_processor,\n",
        "               output_text_processor):\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.input_text_processor = input_text_processor\n",
        "    self.output_text_processor = output_text_processor\n",
        "\n",
        "    self.output_token_string_from_index = (\n",
        "        tf.keras.layers.experimental.preprocessing.StringLookup(\n",
        "            vocabulary=output_text_processor.get_vocabulary(),\n",
        "            mask_token='',\n",
        "            invert=True))\n",
        "\n",
        "    # The output should never generate padding, unknown, or start.\n",
        "    index_from_string = tf.keras.layers.experimental.preprocessing.StringLookup(\n",
        "        vocabulary=output_text_processor.get_vocabulary(), mask_token='')\n",
        "    token_mask_ids = index_from_string(['', '[UNK]', '[START]']).numpy()\n",
        "\n",
        "    token_mask = np.zeros([index_from_string.vocabulary_size()], dtype=np.bool)\n",
        "    token_mask[np.array(token_mask_ids)] = True\n",
        "    self.token_mask = token_mask\n",
        "\n",
        "    self.start_token = index_from_string('[START]')\n",
        "    self.end_token = index_from_string('[END]')"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T18:04:19.535376Z",
          "iopub.status.busy": "2021-08-11T18:04:19.534538Z",
          "iopub.status.idle": "2021-08-11T18:04:19.536855Z",
          "shell.execute_reply": "2021-08-11T18:04:19.536432Z"
        },
        "id": "PO-CLL1LVBbM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "translator = Translator(\n",
        "    encoder=train_translator.encoder,\n",
        "    decoder=train_translator.decoder,\n",
        "    input_text_processor=input_text_processor,\n",
        "    output_text_processor=output_text_processor,\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T18:04:19.541227Z",
          "iopub.status.busy": "2021-08-11T18:04:19.540665Z",
          "iopub.status.idle": "2021-08-11T18:04:19.633409Z",
          "shell.execute_reply": "2021-08-11T18:04:19.633933Z"
        },
        "id": "iBQzFZ9uWU79"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chuyển đổi các token ID thành văn bản\n",
        "\n",
        "Phương thức đầu tiên để thực hiện là `tokens_to_text` mà chuyển đổi từ các token ID thành văn bản có thể đọc được."
      ],
      "metadata": {
        "id": "b59PN-UxqYrU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def tokens_to_text(self, result_tokens):\n",
        "  shape_checker = ShapeChecker()\n",
        "  shape_checker(result_tokens, ('batch', 't'))\n",
        "  result_text_tokens = self.output_token_string_from_index(result_tokens)\n",
        "  shape_checker(result_text_tokens, ('batch', 't'))\n",
        "\n",
        "  result_text = tf.strings.reduce_join(result_text_tokens,\n",
        "                                       axis=1, separator=' ')\n",
        "  shape_checker(result_text, ('batch'))\n",
        "\n",
        "  result_text = tf.strings.strip(result_text)\n",
        "  shape_checker(result_text, ('batch',))\n",
        "  return result_text"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T18:04:19.640830Z",
          "iopub.status.busy": "2021-08-11T18:04:19.640051Z",
          "iopub.status.idle": "2021-08-11T18:04:19.642114Z",
          "shell.execute_reply": "2021-08-11T18:04:19.642540Z"
        },
        "id": "8IjwKTwtmdFf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "Translator.tokens_to_text = tokens_to_text"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T18:04:19.646598Z",
          "iopub.status.busy": "2021-08-11T18:04:19.645940Z",
          "iopub.status.idle": "2021-08-11T18:04:19.648436Z",
          "shell.execute_reply": "2021-08-11T18:04:19.647961Z"
        },
        "id": "912aV0K7r90w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nhập một số token ID ngẫu nhiên và xem những gì nó tạo ra:"
      ],
      "metadata": {
        "id": "krBuAapkqNs9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "example_output_tokens = tf.random.uniform(\n",
        "    shape=[5, 2], minval=0, dtype=tf.int64,\n",
        "    maxval=output_text_processor.vocabulary_size())\n",
        "translator.tokens_to_text(example_output_tokens).numpy()"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T18:04:19.653286Z",
          "iopub.status.busy": "2021-08-11T18:04:19.652631Z",
          "iopub.status.idle": "2021-08-11T18:04:19.658828Z",
          "shell.execute_reply": "2021-08-11T18:04:19.659219Z"
        },
        "id": "cWCMHdoS32QN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Các mẫu dự đoán từ bộ giải mã\n",
        "\n",
        "Hàm này nhận các kết quả đầu ra logit của bộ giải mã và lấy mẫu các token ID từ bản phân phối đó:"
      ],
      "metadata": {
        "id": "AC9De_kAqtaE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def sample(self, logits, temperature):\n",
        "  shape_checker = ShapeChecker()\n",
        "  # 't' is usually 1 here.\n",
        "  shape_checker(logits, ('batch', 't', 'vocab'))\n",
        "  shape_checker(self.token_mask, ('vocab',))\n",
        "\n",
        "  token_mask = self.token_mask[tf.newaxis, tf.newaxis, :]\n",
        "  shape_checker(token_mask, ('batch', 't', 'vocab'), broadcast=True)\n",
        "\n",
        "  # Set the logits for all masked tokens to -inf, so they are never chosen.\n",
        "  logits = tf.where(self.token_mask, -np.inf, logits)\n",
        "\n",
        "  if temperature == 0.0:\n",
        "    new_tokens = tf.argmax(logits, axis=-1)\n",
        "  else: \n",
        "    logits = tf.squeeze(logits, axis=1)\n",
        "    new_tokens = tf.random.categorical(logits/temperature,\n",
        "                                        num_samples=1)\n",
        "  \n",
        "  shape_checker(new_tokens, ('batch', 't'))\n",
        "\n",
        "  return new_tokens"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T18:04:19.665908Z",
          "iopub.status.busy": "2021-08-11T18:04:19.665195Z",
          "iopub.status.idle": "2021-08-11T18:04:19.667681Z",
          "shell.execute_reply": "2021-08-11T18:04:19.667192Z"
        },
        "id": "8lfuj3GcdD6e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "Translator.sample = sample"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T18:04:19.671752Z",
          "iopub.status.busy": "2021-08-11T18:04:19.670928Z",
          "iopub.status.idle": "2021-08-11T18:04:19.673220Z",
          "shell.execute_reply": "2021-08-11T18:04:19.672743Z"
        },
        "id": "4DpDnBdBdL9_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chạy thử chức năng này trên một số đầu vào ngẫu nhiên:"
      ],
      "metadata": {
        "id": "QwdHfGEfsmy5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "example_logits = tf.random.normal([5, 1, output_text_processor.vocabulary_size()])\n",
        "example_output_tokens = translator.sample(example_logits, temperature=1.0)\n",
        "example_output_tokens"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T18:04:19.678033Z",
          "iopub.status.busy": "2021-08-11T18:04:19.677427Z",
          "iopub.status.idle": "2021-08-11T18:04:19.685173Z",
          "shell.execute_reply": "2021-08-11T18:04:19.684709Z"
        },
        "id": "rwLT0nxXym80"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Triển khai vòng lặp dịch\n",
        "\n",
        "Đây là một triển khai hoàn chỉnh của vòng lặp dịch văn bản sang văn bản.\n",
        "\n",
        "Điều này thực hiện thu thập các kết quả vào danh sách python, trước khi sử dụng `tf.concat` tham gia cùng chúng vào các tensor.\n",
        "\n",
        "Điều này thực hiện tĩnh gỡ cuộn tròn đồ thị lặp `max_length`. Điều này không sao với việc thực thi khát vọng trong python."
      ],
      "metadata": {
        "id": "NEWIKFIJ2HWM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def translate_unrolled(self,\n",
        "                       input_text, *,\n",
        "                       max_length=50,\n",
        "                       return_attention=True,\n",
        "                       temperature=1.0):\n",
        "  batch_size = tf.shape(input_text)[0]\n",
        "  input_tokens = self.input_text_processor(input_text)\n",
        "  enc_output, enc_state = self.encoder(input_tokens)\n",
        "\n",
        "  dec_state = enc_state\n",
        "  new_tokens = tf.fill([batch_size, 1], self.start_token)\n",
        "\n",
        "  result_tokens = []\n",
        "  attention = []\n",
        "  done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
        "\n",
        "  for _ in range(max_length):\n",
        "    dec_input = DecoderInput(new_tokens=new_tokens,\n",
        "                             enc_output=enc_output,\n",
        "                             mask=(input_tokens!=0))\n",
        "    \n",
        "    dec_result, dec_state = self.decoder(dec_input, state=dec_state)\n",
        "\n",
        "    attention.append(dec_result.attention_weights)\n",
        "\n",
        "    new_tokens = self.sample(dec_result.logits, temperature)\n",
        "\n",
        "    # If a sequence produces an `end_token`, set it `done`\n",
        "    done = done | (new_tokens == self.end_token)\n",
        "    # Once a sequence is done it only produces 0-padding.\n",
        "    new_tokens = tf.where(done, tf.constant(0, dtype=tf.int64), new_tokens)\n",
        "\n",
        "    # Collect the generated tokens\n",
        "    result_tokens.append(new_tokens)\n",
        "\n",
        "    if tf.executing_eagerly() and tf.reduce_all(done):\n",
        "      break\n",
        "\n",
        "  # Convert the list of generates token ids to a list of strings.\n",
        "  result_tokens = tf.concat(result_tokens, axis=-1)\n",
        "  result_text = self.tokens_to_text(result_tokens)\n",
        "\n",
        "  if return_attention:\n",
        "    attention_stack = tf.concat(attention, axis=1)\n",
        "    return {'text': result_text, 'attention': attention_stack}\n",
        "  else:\n",
        "    return {'text': result_text}\n"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T18:04:19.693810Z",
          "iopub.status.busy": "2021-08-11T18:04:19.693087Z",
          "iopub.status.idle": "2021-08-11T18:04:19.695444Z",
          "shell.execute_reply": "2021-08-11T18:04:19.694986Z"
        },
        "id": "ZmOvVrZmwAxg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "Translator.translate = translate_unrolled"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T18:04:19.699489Z",
          "iopub.status.busy": "2021-08-11T18:04:19.698779Z",
          "iopub.status.idle": "2021-08-11T18:04:19.701214Z",
          "shell.execute_reply": "2021-08-11T18:04:19.700763Z"
        },
        "id": "JOmd8Y269MG3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chạy nó trên một đầu vào đơn giản:"
      ],
      "metadata": {
        "id": "NxYXf3GNKKLS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%%time\n",
        "input_text = tf.constant([\n",
        "    'hace mucho frio aqui.', # \"It's really cold here.\"\n",
        "    'Esta es mi vida.', # \"This is my life.\"\"\n",
        "])\n",
        "\n",
        "result = translator.translate(\n",
        "    input_text = input_text)\n",
        "\n",
        "print(result['text'][0].numpy().decode())\n",
        "print(result['text'][1].numpy().decode())\n",
        "print()"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T18:04:19.706437Z",
          "iopub.status.busy": "2021-08-11T18:04:19.705822Z",
          "iopub.status.idle": "2021-08-11T18:04:19.840274Z",
          "shell.execute_reply": "2021-08-11T18:04:19.839836Z"
        },
        "id": "hd2rgyHwVVrv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nếu bạn muốn xuất mô hình này, bạn sẽ cần phải gói phương thức này trong một `tf.function`. Việc triển khai cơ bản này có một số vấn đề nếu bạn cố gắng thực hiện điều đó:\n",
        "\n",
        "1. Các biểu đồ kết quả rất lớn và mất vài giây để tạo, lưu hoặc tải.\n",
        "\n",
        "2. Bạn không thể phá vỡ từ một vòng tĩnh gỡ cuộn tròn, vì vậy nó sẽ luôn luôn chạy lặp `max_length`, ngay cả khi tất cả các kết quả đầu ra được thực hiện. Nhưng thậm chí sau đó nó nhanh hơn một chút so với việc thực thi khát vọng.\n"
      ],
      "metadata": {
        "id": "S-6cFyqeUPQm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "@tf.function(input_signature=[tf.TensorSpec(dtype=tf.string, shape=[None])])\n",
        "def tf_translate(self, input_text):\n",
        "  return self.translate(input_text)\n",
        "\n",
        "Translator.tf_translate = tf_translate"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T18:04:19.845724Z",
          "iopub.status.busy": "2021-08-11T18:04:19.844997Z",
          "iopub.status.idle": "2021-08-11T18:04:19.847043Z",
          "shell.execute_reply": "2021-08-11T18:04:19.847423Z"
        },
        "id": "_JhTZ5hOptO-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chạy `tf.function` một lần để biên dịch nó:"
      ],
      "metadata": {
        "id": "fkccvHDvXCa8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%%time\n",
        "result = translator.tf_translate(\n",
        "    input_text = input_text)"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T18:04:19.853787Z",
          "iopub.status.busy": "2021-08-11T18:04:19.853221Z",
          "iopub.status.idle": "2021-08-11T18:04:36.911685Z",
          "shell.execute_reply": "2021-08-11T18:04:36.912021Z"
        },
        "id": "_NzrixLvVBjQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%%time\n",
        "result = translator.tf_translate(\n",
        "    input_text = input_text)\n",
        "\n",
        "print(result['text'][0].numpy().decode())\n",
        "print(result['text'][1].numpy().decode())\n",
        "print()"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T18:04:36.917261Z",
          "iopub.status.busy": "2021-08-11T18:04:36.916579Z",
          "iopub.status.idle": "2021-08-11T18:04:37.012649Z",
          "shell.execute_reply": "2021-08-11T18:04:37.012181Z"
        },
        "id": "USJdu00tVFbd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#@title [Tuỳ chọn] Sử dụng vòng lặp tượng trưng\n",
        "def translate_symbolic(self,\n",
        "                       input_text,\n",
        "                       *,\n",
        "                       max_length=50,\n",
        "                       return_attention=True,\n",
        "                       temperature=1.0):\n",
        "  shape_checker = ShapeChecker()\n",
        "  shape_checker(input_text, ('batch',))\n",
        "\n",
        "  batch_size = tf.shape(input_text)[0]\n",
        "\n",
        "  # Encode the input\n",
        "  input_tokens = self.input_text_processor(input_text)\n",
        "  shape_checker(input_tokens, ('batch', 's'))\n",
        "\n",
        "  enc_output, enc_state = self.encoder(input_tokens)\n",
        "  shape_checker(enc_output, ('batch', 's', 'enc_units'))\n",
        "  shape_checker(enc_state, ('batch', 'enc_units'))\n",
        "\n",
        "  # Initialize the decoder\n",
        "  dec_state = enc_state\n",
        "  new_tokens = tf.fill([batch_size, 1], self.start_token)\n",
        "  shape_checker(new_tokens, ('batch', 't1'))\n",
        "\n",
        "  # Initialize the accumulators\n",
        "  result_tokens = tf.TensorArray(tf.int64, size=1, dynamic_size=True)\n",
        "  attention = tf.TensorArray(tf.float32, size=1, dynamic_size=True)\n",
        "  done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
        "  shape_checker(done, ('batch', 't1'))\n",
        "\n",
        "  for t in tf.range(max_length):\n",
        "    dec_input = DecoderInput(\n",
        "        new_tokens=new_tokens, enc_output=enc_output, mask=(input_tokens != 0))\n",
        "\n",
        "    dec_result, dec_state = self.decoder(dec_input, state=dec_state)\n",
        "\n",
        "    shape_checker(dec_result.attention_weights, ('batch', 't1', 's'))\n",
        "    attention = attention.write(t, dec_result.attention_weights)\n",
        "\n",
        "    new_tokens = self.sample(dec_result.logits, temperature)\n",
        "    shape_checker(dec_result.logits, ('batch', 't1', 'vocab'))\n",
        "    shape_checker(new_tokens, ('batch', 't1'))\n",
        "\n",
        "    # If a sequence produces an `end_token`, set it `done`\n",
        "    done = done | (new_tokens == self.end_token)\n",
        "    # Once a sequence is done it only produces 0-padding.\n",
        "    new_tokens = tf.where(done, tf.constant(0, dtype=tf.int64), new_tokens)\n",
        "\n",
        "    # Collect the generated tokens\n",
        "    result_tokens = result_tokens.write(t, new_tokens)\n",
        "\n",
        "    if tf.reduce_all(done):\n",
        "      break\n",
        "\n",
        "  # Convert the list of generated token ids to a list of strings.\n",
        "  result_tokens = result_tokens.stack()\n",
        "  shape_checker(result_tokens, ('t', 'batch', 't0'))\n",
        "  result_tokens = tf.squeeze(result_tokens, -1)\n",
        "  result_tokens = tf.transpose(result_tokens, [1, 0])\n",
        "  shape_checker(result_tokens, ('batch', 't'))\n",
        "\n",
        "  result_text = self.tokens_to_text(result_tokens)\n",
        "  shape_checker(result_text, ('batch',))\n",
        "\n",
        "  if return_attention:\n",
        "    attention_stack = attention.stack()\n",
        "    shape_checker(attention_stack, ('t', 'batch', 't1', 's'))\n",
        "\n",
        "    attention_stack = tf.squeeze(attention_stack, 2)\n",
        "    shape_checker(attention_stack, ('t', 'batch', 's'))\n",
        "\n",
        "    attention_stack = tf.transpose(attention_stack, [1, 0, 2])\n",
        "    shape_checker(attention_stack, ('batch', 't', 's'))\n",
        "\n",
        "    return {'text': result_text, 'attention': attention_stack}\n",
        "  else:\n",
        "    return {'text': result_text}"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T18:04:37.025064Z",
          "iopub.status.busy": "2021-08-11T18:04:37.024473Z",
          "iopub.status.idle": "2021-08-11T18:04:37.026279Z",
          "shell.execute_reply": "2021-08-11T18:04:37.026614Z"
        },
        "id": "EbQpyYs13jF_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "Translator.translate = translate_symbolic"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T18:04:37.030402Z",
          "iopub.status.busy": "2021-08-11T18:04:37.029861Z",
          "iopub.status.idle": "2021-08-11T18:04:37.031538Z",
          "shell.execute_reply": "2021-08-11T18:04:37.031887Z"
        },
        "id": "ngywxv1WYO_O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Việc triển khai ban đầu đã sử dụng danh sách python để thu thập kết quả đầu ra. Điều này sử dụng `tf.range` như vòng lặp, cho phép `tf.autograph` để chuyển đổi các vòng lặp. Sự thay đổi lớn nhất trong việc thực hiện này là việc sử dụng `tf.TensorArray` thay vì python `list` để các tensor tích lũy. `tf.TensorArray` được yêu cầu để thu thập một số biến của tensors trong chế độ đồ thị.\n",
        "\n",
        "Với việc thực thi khát vọng, bản triển khai này hoạt động ngang bằng với bản gốc:"
      ],
      "metadata": {
        "id": "lItV7qjEGsYc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%%time\n",
        "result = translator.translate(\n",
        "    input_text = input_text)\n",
        "\n",
        "print(result['text'][0].numpy().decode())\n",
        "print(result['text'][1].numpy().decode())\n",
        "print()"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T18:04:37.036336Z",
          "iopub.status.busy": "2021-08-11T18:04:37.035764Z",
          "iopub.status.idle": "2021-08-11T18:04:37.177999Z",
          "shell.execute_reply": "2021-08-11T18:04:37.178328Z"
        },
        "id": "JRh66y-YYeBw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nhưng khi bạn bọc nó trong một `tf.function` bạn sẽ nhận thấy hai sự khác biệt."
      ],
      "metadata": {
        "id": "l6B8W4_MZdX0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "@tf.function(input_signature=[tf.TensorSpec(dtype=tf.string, shape=[None])])\n",
        "def tf_translate(self, input_text):\n",
        "  return self.translate(input_text)\n",
        "\n",
        "Translator.tf_translate = tf_translate"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T18:04:37.183230Z",
          "iopub.status.busy": "2021-08-11T18:04:37.182676Z",
          "iopub.status.idle": "2021-08-11T18:04:37.184639Z",
          "shell.execute_reply": "2021-08-11T18:04:37.184238Z"
        },
        "id": "WX6EF8KtYh20"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Đầu tiên: Biểu đồ sáng tạo là nhanh hơn nhiều (~ 10 lần), vì nó không tạo các bản sao `max_iterations` của mô hình."
      ],
      "metadata": {
        "id": "9S0kQ-bBZswZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%%time\n",
        "result = translator.tf_translate(\n",
        "    input_text = input_text)"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T18:04:37.189445Z",
          "iopub.status.busy": "2021-08-11T18:04:37.188846Z",
          "iopub.status.idle": "2021-08-11T18:04:38.210799Z",
          "shell.execute_reply": "2021-08-11T18:04:38.211235Z"
        },
        "id": "Eq8d40RKYoJa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thứ hai: Hàm đã biên dịch nhanh hơn nhiều trên các đầu vào nhỏ (5 lần trong ví dụ này), vì nó có thể thoát ra khỏi vòng lặp."
      ],
      "metadata": {
        "id": "2ABEwtKIZ6eE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%%time\n",
        "result = translator.tf_translate(\n",
        "    input_text = input_text)\n",
        "\n",
        "print(result['text'][0].numpy().decode())\n",
        "print(result['text'][1].numpy().decode())\n",
        "print()"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T18:04:38.216811Z",
          "iopub.status.busy": "2021-08-11T18:04:38.216056Z",
          "iopub.status.idle": "2021-08-11T18:04:38.238533Z",
          "shell.execute_reply": "2021-08-11T18:04:38.238908Z"
        },
        "id": "d5VdCLxPYrpz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Trực quan quá trình\n",
        "\n",
        "Các trọng số chú ý được trả về bởi phương thức `translate` cho thấy nơi mô hình là \"đang tìm kiếm\" khi nó được tạo ra mỗi token đầu ra.\n",
        "\n",
        "Vì vậy, tổng sự chú ý trên đầu vào sẽ trả về tất cả những thứ:"
      ],
      "metadata": {
        "id": "eo5sf4jZaO2l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "a = result['attention'][0]\n",
        "\n",
        "print(np.sum(a, axis=-1))"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T18:04:38.243089Z",
          "iopub.status.busy": "2021-08-11T18:04:38.242457Z",
          "iopub.status.idle": "2021-08-11T18:04:38.245329Z",
          "shell.execute_reply": "2021-08-11T18:04:38.244942Z"
        },
        "id": "UEd2GljgqQ-0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Đây là sự phân bố sự chú ý cho bước đầu ra đầu tiên của ví dụ đầu tiên. Lưu ý rằng sự chú ý bây giờ tập trung hơn nhiều so với mô hình chưa được huấn luyện:"
      ],
      "metadata": {
        "id": "k_HWQHcI2_h5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "_ = plt.bar(range(len(a[0, :])), a[0, :])"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T18:04:38.249439Z",
          "iopub.status.busy": "2021-08-11T18:04:38.248860Z",
          "iopub.status.idle": "2021-08-11T18:04:38.359213Z",
          "shell.execute_reply": "2021-08-11T18:04:38.359591Z"
        },
        "id": "M8BHdqQujALu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vì có một số căn chỉnh sơ bộ giữa các từ đầu vào và đầu ra, bạn mong đợi sự chú ý sẽ được tập trung gần đường chéo:"
      ],
      "metadata": {
        "id": "qB13OG472Z3V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plt.imshow(np.array(a), vmin=0.0)"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T18:04:38.373264Z",
          "iopub.status.busy": "2021-08-11T18:04:38.364048Z",
          "iopub.status.idle": "2021-08-11T18:04:38.470091Z",
          "shell.execute_reply": "2021-08-11T18:04:38.470455Z"
        },
        "id": "xyeXuEYHd0kQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dưới đây là một số mã để tạo ra một đồ thị chú ý tốt hơn:"
      ],
      "metadata": {
        "id": "mXECcNTn2mxN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#@title Đồ thị chú ý có nhãn\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "  sentence = tf_lower_and_split_punct(sentence).numpy().decode().split()\n",
        "  predicted_sentence = predicted_sentence.numpy().decode().split() + ['[END]']\n",
        "  fig = plt.figure(figsize=(10, 10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "\n",
        "  attention = attention[:len(predicted_sentence), :len(sentence)]\n",
        "\n",
        "  ax.matshow(attention, cmap='viridis', vmin=0.0)\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  ax.set_xlabel('Input text')\n",
        "  ax.set_ylabel('Output text')\n",
        "  plt.suptitle('Attention weights')"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T18:04:38.477252Z",
          "iopub.status.busy": "2021-08-11T18:04:38.476636Z",
          "iopub.status.idle": "2021-08-11T18:04:38.478771Z",
          "shell.execute_reply": "2021-08-11T18:04:38.478338Z"
        },
        "id": "s5hQWlbN3jGF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "i=0\n",
        "plot_attention(result['attention'][i], input_text[i], result['text'][i])"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T18:04:38.482887Z",
          "iopub.status.busy": "2021-08-11T18:04:38.482226Z",
          "iopub.status.idle": "2021-08-11T18:04:38.665510Z",
          "shell.execute_reply": "2021-08-11T18:04:38.665037Z"
        },
        "id": "rrGawQv2eiA4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dịch thêm một vài câu và vẽ sơ đồ:"
      ],
      "metadata": {
        "id": "JHBdOf9duumm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%%time\n",
        "three_input_text = tf.constant([\n",
        "    # This is my life.\n",
        "    'Esta es mi vida.',\n",
        "    # Are they still home?\n",
        "    '¿Todavía están en casa?',\n",
        "    # Try to find out.'\n",
        "    'Tratar de descubrir.',\n",
        "])\n",
        "\n",
        "result = translator.tf_translate(three_input_text)\n",
        "\n",
        "for tr in result['text']:\n",
        "  print(tr.numpy().decode())\n",
        "\n",
        "print()"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T18:04:38.671490Z",
          "iopub.status.busy": "2021-08-11T18:04:38.670628Z",
          "iopub.status.idle": "2021-08-11T18:04:38.696011Z",
          "shell.execute_reply": "2021-08-11T18:04:38.696442Z"
        },
        "id": "WrAM0FDomq3E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "result['text']"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T18:04:38.701522Z",
          "iopub.status.busy": "2021-08-11T18:04:38.700679Z",
          "iopub.status.idle": "2021-08-11T18:04:38.703955Z",
          "shell.execute_reply": "2021-08-11T18:04:38.704312Z"
        },
        "id": "-LjFp0AljOaZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "i = 0\n",
        "plot_attention(result['attention'][i], three_input_text[i], result['text'][i])"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T18:04:38.709097Z",
          "iopub.status.busy": "2021-08-11T18:04:38.708136Z",
          "iopub.status.idle": "2021-08-11T18:04:38.885129Z",
          "shell.execute_reply": "2021-08-11T18:04:38.885478Z"
        },
        "id": "v7QwIMrG-id2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "i = 1\n",
        "plot_attention(result['attention'][i], three_input_text[i], result['text'][i])"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T18:04:38.891069Z",
          "iopub.status.busy": "2021-08-11T18:04:38.890166Z",
          "iopub.status.idle": "2021-08-11T18:04:39.056350Z",
          "shell.execute_reply": "2021-08-11T18:04:39.055837Z"
        },
        "id": "zYVoVf8P-lr-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "i = 2\n",
        "plot_attention(result['attention'][i], three_input_text[i], result['text'][i])"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T18:04:39.061791Z",
          "iopub.status.busy": "2021-08-11T18:04:39.060791Z",
          "iopub.status.idle": "2021-08-11T18:04:39.224150Z",
          "shell.execute_reply": "2021-08-11T18:04:39.223651Z"
        },
        "id": "9sFvlZBk-me4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Các câu ngắn thường hoạt động tốt, nhưng nếu đầu vào quá dài, mô hình sẽ mất tập trung theo đúng nghĩa đen và ngừng cung cấp các dự đoán hợp lý. Có hai lý do chính cho việc này:\n",
        "\n",
        "1. Mô hình đã được huấn luyện với việc teacher-forcing cung cấp đúng token ở mỗi bước, bất kể dự đoán của mô hình. Mô hình có thể được thực hiện mạnh mẽ hơn nếu đôi khi nó được cung cấp các dự đoán của chính nó.\n",
        "\n",
        "2. Mô hình chỉ có quyền truy cập vào đầu ra trước đó của nó thông qua trạng thái RNN. Nếu trạng thái RNN bị hỏng, không có cách nào để mô hình phục hồi. [Transformers](https://www.tensorflow.org/text/tutorials/transformer) giải quyết điều này bằng cách sử dụng tự chú ý trong bộ mã hóa và giải mã."
      ],
      "metadata": {
        "id": "rA3xI3NzrRJt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "long_input_text = tf.constant([inp[-1]])\n",
        "\n",
        "import textwrap\n",
        "print('Expected output:\\n', '\\n'.join(textwrap.wrap(targ[-1])))"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T18:04:39.229369Z",
          "iopub.status.busy": "2021-08-11T18:04:39.228582Z",
          "iopub.status.idle": "2021-08-11T18:04:39.232178Z",
          "shell.execute_reply": "2021-08-11T18:04:39.232501Z"
        },
        "id": "-FUHFLEvSMbG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "result = translator.tf_translate(long_input_text)\n",
        "\n",
        "i = 0\n",
        "plot_attention(result['attention'][i], long_input_text[i], result['text'][i])\n",
        "_ = plt.suptitle('This never works')"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T18:04:39.237625Z",
          "iopub.status.busy": "2021-08-11T18:04:39.236704Z",
          "iopub.status.idle": "2021-08-11T18:04:40.733405Z",
          "shell.execute_reply": "2021-08-11T18:04:40.733812Z"
        },
        "id": "lDa_8NaN_RUy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Xuất\n",
        "\n",
        "Một khi bạn có một mô hình đang hài lòng, bạn có thể muốn xuất nó như là một `tf.saved_model` để sử dụng bên ngoài chương trình python này đã tạo ra nó.\n",
        "\n",
        "Từ mô hình này là một lớp con của `tf.Module` (thông qua `keras.Model`), và tất cả các hàm phục vụ xuất được biên dịch trong một `tf.function` mô hình nên xuất sạch với `tf.saved_model.save`:\n",
        "\n",
        "Bây giờ mà hàm đã được bắt nguồn từ nó có thể được xuất sử dụng `saved_model.save`:"
      ],
      "metadata": {
        "id": "mMA9Pp71nzH9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "tf.saved_model.save(translator, 'translator',\n",
        "                    signatures={'serving_default': translator.tf_translate})"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T18:04:40.741712Z",
          "iopub.status.busy": "2021-08-11T18:04:40.738525Z",
          "iopub.status.idle": "2021-08-11T18:04:45.053047Z",
          "shell.execute_reply": "2021-08-11T18:04:45.053440Z"
        },
        "id": "OyvxT5V0_X5B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "reloaded = tf.saved_model.load('translator')\n",
        "result = reloaded.tf_translate(three_input_text)"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T18:04:45.069094Z",
          "iopub.status.busy": "2021-08-11T18:04:45.068440Z",
          "iopub.status.idle": "2021-08-11T18:04:46.796415Z",
          "shell.execute_reply": "2021-08-11T18:04:46.796782Z"
        },
        "id": "-I0j3i3ekOba"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%%time\n",
        "result = reloaded.tf_translate(three_input_text)\n",
        "\n",
        "for tr in result['text']:\n",
        "  print(tr.numpy().decode())\n",
        "\n",
        "print()"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-11T18:04:46.802226Z",
          "iopub.status.busy": "2021-08-11T18:04:46.801491Z",
          "iopub.status.idle": "2021-08-11T18:04:46.827007Z",
          "shell.execute_reply": "2021-08-11T18:04:46.826511Z"
        },
        "id": "GXZF__FZXJCm"
      }
    }
  ]
}