{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "transformer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_qNSzzyaCbD"
      },
      "source": [
        "Copyright 2019 The TensorFlow Authors.\n",
        "\n",
        "```\n",
        "@title Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "https://www.apache.org/licenses/LICENSE-2.0\n",
        "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0Qjg6vuaHNt"
      },
      "source": [
        "# Mô hình Transformer để hiểu ngôn ngữ\n",
        "\n",
        "Đây hướng dẫn huấn luyện một <a href=\"https://arxiv.org/abs/1706.03762\" class=\"external\">mô hình Transformer</a> để dịch một [tập dữ liệu Bồ Đào Nha sang tiếng Anh](https://www.tensorflow.org/datasets/catalog/ted_hrlr_translate#ted_hrlr_translatept_to_en). Đây là một ví dụ nâng cao mà giả định kiến thức của [sinh văn bản](https://www.tensorflow.org/text/tutorials/text_generation) và [chú ý](https://www.tensorflow.org/text/tutorials/nmt_with_attention).\n",
        "\n",
        "Ý tưởng cốt lõi đằng sau mô hình Transformer là *tự chú ý* - khả năng tham gia vào các vị trí khác nhau của chuỗi đầu vào để tính một đại diện của chuỗi đó. Transformer tạo ngăn xếp của các lớp tự chú ý và được giải thích dưới đây trong các phần *Scaled dot product attention* và *Multi-head attention*.\n",
        "\n",
        "Một mô hình transformer xử lý đầu vào có kích thước thay đổi sử dụng ngăn xếp của các lớp tự chú ý thay vì [các RNN](https://www.tensorflow.org/text/tutorials/text_classification_rnn) hoặc [các CNN](https://www.tensorflow.org/tutorials/images/cnn). Kiến trúc chung này có một số ưu điểm:\n",
        "\n",
        "* Nó không đưa ra giả định về các mối quan hệ thời gian/không gian trên dữ liệu. Đây là lý tưởng cho việc xử lý một tập các đối tượng (ví dụ, [đơn vị StarCraft](https://deepmind.com/blog/alphastar-mastering-real-time-strategy-game-starcraft-ii/#block-8)).\n",
        "\n",
        "* Các kết quả đầu ra của lớp có thể được tính toán song song, thay vì một chuỗi như RNN.\n",
        "\n",
        "* Các mục xa có thể ảnh hưởng đến đầu ra của nhau mà không đi qua nhiều RNN-bước, hoặc các lớp tích chập (xem ví dụ [Scene Memory Transformer](https://arxiv.org/pdf/1903.03878.pdf)).\n",
        "\n",
        "* Nó có thể học các phụ thuộc dài hạn. Đây là một thách thức trong nhiều nhiệm vụ chuỗi.\n",
        "\n",
        "Nhược điểm của kiến ​​trúc này là:\n",
        "\n",
        "* Đối với một chuỗi thời gian, đầu ra cho một bước thời gian được tính từ *toàn bộ lịch sử* thay vì chỉ có đầu vào và trạng thái ẩn hiện tại. Điều này *có thể* kém hiệu quả.\n",
        "\n",
        "* Nếu đầu vào không có một mối quan hệ thời gian/không gian, như văn bản, một số mã hóa vị trí phải được bổ sung hoặc các mô hình sẽ nhìn thấy một túi từ có hiệu quả.\n",
        "\n",
        "Sau khi huấn luyện mô hình trong sổ tay này, bạn sẽ có thể nhập một câu tiếng Bồ Đào Nha và gửi lại bản dịch tiếng Anh.\n",
        "\n",
        "![attention_map_portuguese](img/attention_map_portuguese.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swymtxpl7W7w"
      },
      "source": [
        "## Cài đặt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:11:17.324995Z",
          "iopub.status.busy": "2021-08-25T11:11:17.324401Z",
          "iopub.status.idle": "2021-08-25T11:11:20.429550Z",
          "shell.execute_reply": "2021-08-25T11:11:20.428990Z"
        },
        "id": "XFG0NDRu5mYQ"
      },
      "source": [
        "!pip install tensorflow_datasets\n",
        "!pip install -U tensorflow-text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:11:20.434816Z",
          "iopub.status.busy": "2021-08-25T11:11:20.434262Z",
          "iopub.status.idle": "2021-08-25T11:11:22.672326Z",
          "shell.execute_reply": "2021-08-25T11:11:22.672695Z"
        },
        "id": "JjJJyJTZYebt"
      },
      "source": [
        "import collections\n",
        "import logging\n",
        "import os\n",
        "import pathlib\n",
        "import re\n",
        "import string\n",
        "import sys\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_text as text\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:11:22.677244Z",
          "iopub.status.busy": "2021-08-25T11:11:22.676636Z",
          "iopub.status.idle": "2021-08-25T11:11:22.678165Z",
          "shell.execute_reply": "2021-08-25T11:11:22.678488Z"
        },
        "id": "pXzVhU34zWEU"
      },
      "source": [
        "logging.getLogger('tensorflow').setLevel(logging.ERROR)  # suppress warnings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cCvXbPkccV1"
      },
      "source": [
        "## Tải xuống tập dữ liệu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4_Qt8W1hJE_"
      },
      "source": [
        "Sử dụng [tập dữ liệu TensorFlow](https://www.tensorflow.org/datasets) để tải [tập dữ liệu dịch tiếng Bồ Đào nha-Anh](https://github.com/neulab/word-embeddings-for-nmt) từ [Dự án Dịch Mở TED Talks](https://www.ted.com/participate/translate).\n",
        "\n",
        "Tập dữ liệu này chứa khoảng 50000 ví dụ đào tạo, 1100 ví dụ xác thực và 2000 ví dụ kiểm tra."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:11:22.682639Z",
          "iopub.status.busy": "2021-08-25T11:11:22.682105Z",
          "iopub.status.idle": "2021-08-25T11:11:26.933207Z",
          "shell.execute_reply": "2021-08-25T11:11:26.933579Z"
        },
        "id": "8q9t4FmN96eN"
      },
      "source": [
        "examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en', with_info=True,\n",
        "                               as_supervised=True)\n",
        "train_examples, val_examples = examples['train'], examples['validation']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OnwQZ2IpTbl"
      },
      "source": [
        "Đối tượng `tf.data.Dataset` được trả về  bởi tập dữ liệu TensorFlow các cặp ví dụ văn bản:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:11:26.939178Z",
          "iopub.status.busy": "2021-08-25T11:11:26.938574Z",
          "iopub.status.idle": "2021-08-25T11:11:27.703016Z",
          "shell.execute_reply": "2021-08-25T11:11:27.702566Z"
        },
        "id": "AtuMLTQGlHZ1"
      },
      "source": [
        "for pt_examples, en_examples in train_examples.batch(3).take(1):\n",
        "  for pt in pt_examples.numpy():\n",
        "    print(pt.decode('utf-8'))\n",
        "\n",
        "  print()\n",
        "\n",
        "  for en in en_examples.numpy():\n",
        "    print(en.decode('utf-8'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJxTd6aVnZyh"
      },
      "source": [
        "## Token hoá văn bản & giải token hoá\n",
        "\n",
        "Bạn không thể huấn luyện một mô hình trực tiếp trên văn bản. Trước tiên, văn bản cần được chuyển đổi thành một vài biểu diễn số. Thông thường, bạn chuyển đổi văn bản thành chuỗi token ID mà được sử dụng làm chỉ số thành một bản nhúng.\n",
        "\n",
        "Một triển khai phổ biến được thể hiện trong [Hướng dẫn tokenizer từ con](https://www.tensorflow.org/text/guide/subwords_tokenizer) xây dựng các tokenizer từ con ([`text.BertTokenizer`](https://www.tensorflow.org/text/api_docs/python/text/BertTokenizer)) được tối ưu hóa cho tập dữ liệu này và xuất chúng trong một [saved_model](https://www.tensorflow.org/guide/saved_model).\n",
        "\n",
        "Tải về, giải nén và nhập các `saved_model`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:11:27.709286Z",
          "iopub.status.busy": "2021-08-25T11:11:27.707628Z",
          "iopub.status.idle": "2021-08-25T11:11:27.916666Z",
          "shell.execute_reply": "2021-08-25T11:11:27.916226Z"
        },
        "id": "QToMl0NanZPr"
      },
      "source": [
        "model_name = \"ted_hrlr_translate_pt_en_converter\"\n",
        "tf.keras.utils.get_file(\n",
        "    f\"{model_name}.zip\",\n",
        "    f\"https://storage.googleapis.com/download.tensorflow.org/models/{model_name}.zip\",\n",
        "    cache_dir='.', cache_subdir='', extract=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:11:27.920617Z",
          "iopub.status.busy": "2021-08-25T11:11:27.920080Z",
          "iopub.status.idle": "2021-08-25T11:11:28.764441Z",
          "shell.execute_reply": "2021-08-25T11:11:28.763950Z"
        },
        "id": "h5dbGnPXnuI1"
      },
      "source": [
        "tokenizers = tf.saved_model.load(model_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQYc0CJTpnvg"
      },
      "source": [
        "Các `tf.saved_model` chứa hai tokenizer văn bản, một cho tiếng Anh và một cho tiếng Bồ Đào Nha. Cả hai đều có các phương pháp giống nhau:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:11:28.769689Z",
          "iopub.status.busy": "2021-08-25T11:11:28.769101Z",
          "iopub.status.idle": "2021-08-25T11:11:28.771177Z",
          "shell.execute_reply": "2021-08-25T11:11:28.771527Z"
        },
        "id": "s-PCJijfcZ9_"
      },
      "source": [
        "[item for item in dir(tokenizers.en) if not item.startswith('_')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pv_nc5lrAiD"
      },
      "source": [
        "Phương pháp `tokenize` chuyển đổi một lô các chuỗi đến một đệm-lô các token ID. Phương pháp này tách dấu câu, chữ thường và unicode-chuẩn hóa đầu vào trước khi mã hóa. Sự chuẩn hóa đó không hiển thị ở đây vì dữ liệu đầu vào đã được chuẩn hóa."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:11:28.775278Z",
          "iopub.status.busy": "2021-08-25T11:11:28.774754Z",
          "iopub.status.idle": "2021-08-25T11:11:28.777179Z",
          "shell.execute_reply": "2021-08-25T11:11:28.776731Z"
        },
        "id": "0GV-smAAQJtM"
      },
      "source": [
        "for en in en_examples.numpy():\n",
        "  print(en.decode('utf-8'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:11:28.781507Z",
          "iopub.status.busy": "2021-08-25T11:11:28.780275Z",
          "iopub.status.idle": "2021-08-25T11:11:29.005148Z",
          "shell.execute_reply": "2021-08-25T11:11:29.005555Z"
        },
        "id": "2fQJq1xB-tOn"
      },
      "source": [
        "encoded = tokenizers.en.tokenize(en_examples)\n",
        "\n",
        "for row in encoded.to_list():\n",
        "  print(row)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBRlikwDR2Lu"
      },
      "source": [
        "Phương pháp `detokenize` thực hiện chuyển đổi các token ID thành văn bản dễ đọc của con người:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:11:29.010789Z",
          "iopub.status.busy": "2021-08-25T11:11:29.010087Z",
          "iopub.status.idle": "2021-08-25T11:11:29.115602Z",
          "shell.execute_reply": "2021-08-25T11:11:29.115931Z"
        },
        "id": "Tpqx1aug3W31"
      },
      "source": [
        "round_trip = tokenizers.en.detokenize(encoded)\n",
        "for line in round_trip.numpy():\n",
        "  print(line.decode('utf-8'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5mGvytArL9g"
      },
      "source": [
        "Cấp thấp phương pháp `lookup` chuyển đổi từ các token ID thành token văn bản:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:11:29.121066Z",
          "iopub.status.busy": "2021-08-25T11:11:29.120470Z",
          "iopub.status.idle": "2021-08-25T11:11:29.135675Z",
          "shell.execute_reply": "2021-08-25T11:11:29.135996Z"
        },
        "id": "RpzRLzvIuN3R"
      },
      "source": [
        "tokens = tokenizers.en.lookup(encoded)\n",
        "tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5V8Ix_PNSfhV"
      },
      "source": [
        "Ở đây bạn có thể thấy khía cạnh \"subword\" của các tokenizer. Từ `\"searchability\"` được tách thành `\"search ##ability\"` và từ `\"serendipity\"` thành `\"s ##rect ##nd ##ip ##ity\"`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fd1NWMxjfsDd"
      },
      "source": [
        "## Cài đặt đường tin đầu vào"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7JHK7N7tNZy"
      },
      "source": [
        "Để xây dựng một đường tin đầu vào phù hợp cho việc huấn luyện, bạn sẽ áp dụng một số biến đổi cho tập dữ liệu.\n",
        "\n",
        "Hàm này sẽ được sử dụng để mã hóa các lô văn bản thô:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:11:29.140391Z",
          "iopub.status.busy": "2021-08-25T11:11:29.139815Z",
          "iopub.status.idle": "2021-08-25T11:11:29.141590Z",
          "shell.execute_reply": "2021-08-25T11:11:29.141908Z"
        },
        "id": "6shgzEck3FiV"
      },
      "source": [
        "def tokenize_pairs(pt, en):\n",
        "    pt = tokenizers.pt.tokenize(pt)\n",
        "    # Convert from ragged to dense, padding with zeros.\n",
        "    pt = pt.to_tensor()\n",
        "\n",
        "    en = tokenizers.en.tokenize(en)\n",
        "    # Convert from ragged to dense, padding with zeros.\n",
        "    en = en.to_tensor()\n",
        "    return pt, en"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cf2HwC_0wG0v"
      },
      "source": [
        "Đây là một đường tin đầu vào đơn giản có thể xử lý, xáo trộn và phân lô dữ liệu:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:11:29.145462Z",
          "iopub.status.busy": "2021-08-25T11:11:29.144903Z",
          "iopub.status.idle": "2021-08-25T11:11:29.146887Z",
          "shell.execute_reply": "2021-08-25T11:11:29.146374Z"
        },
        "id": "bcRp7VcQ5m6g"
      },
      "source": [
        "BUFFER_SIZE = 20000\n",
        "BATCH_SIZE = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:11:29.150972Z",
          "iopub.status.busy": "2021-08-25T11:11:29.150461Z",
          "iopub.status.idle": "2021-08-25T11:11:29.331884Z",
          "shell.execute_reply": "2021-08-25T11:11:29.332257Z"
        },
        "id": "BUN_jLBTwNxk"
      },
      "source": [
        "def make_batches(ds):\n",
        "  return (\n",
        "      ds\n",
        "      .cache()\n",
        "      .shuffle(BUFFER_SIZE)\n",
        "      .batch(BATCH_SIZE)\n",
        "      .map(tokenize_pairs, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "      .prefetch(tf.data.AUTOTUNE))\n",
        "\n",
        "\n",
        "train_batches = make_batches(train_examples)\n",
        "val_batches = make_batches(val_examples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBQuibYA4n0n"
      },
      "source": [
        "## Mã hoá vị trí\n",
        "\n",
        "Các lớp chú ý xem đầu vào của chúng là một tập hợp các vectơ, không có thứ tự tuần tự. Mô hình này cũng không chứa bất kỳ lớp đệ quy hoặc tích chập nào. Do đó, một \"mã hóa vị trí\" được thêm vào để cung cấp cho mô hình một số thông tin về vị trí tương đối của các token trong câu.\n",
        "\n",
        "Vectơ mã hóa vị trí được thêm vào vectơ nhúng. Nhúng đại diện cho một token trong không gian *d* chiều nơi các token có nghĩa tương tự sẽ gần nhau hơn. Nhưng các nhúng không mã hóa vị trí tương đối của các token trong một câu. Vì vậy, sau khi thêm mã hóa vị trí, các token sẽ gần nhau hơn dựa trên *sự tương đồng nghĩa của chúng và vị trí của chúng trong câu*, trong không gian *d* chiều.\n",
        "\n",
        "Công thức tính toán mã hóa vị trí như sau:\n",
        "\n",
        "$$\\Large{PE_{(pos, 2i)} = \\sin(pos / 10000^{2i / d_{model}})}$$\n",
        "$$\\Large{PE_{(pos, 2i+1)} = \\cos(pos / 10000^{2i / d_{model}})}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:11:29.336743Z",
          "iopub.status.busy": "2021-08-25T11:11:29.336205Z",
          "iopub.status.idle": "2021-08-25T11:11:29.337824Z",
          "shell.execute_reply": "2021-08-25T11:11:29.338152Z"
        },
        "id": "WhIOZjMNKujn"
      },
      "source": [
        "def get_angles(pos, i, d_model):\n",
        "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "  return pos * angle_rates"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:11:29.343214Z",
          "iopub.status.busy": "2021-08-25T11:11:29.342689Z",
          "iopub.status.idle": "2021-08-25T11:11:29.344835Z",
          "shell.execute_reply": "2021-08-25T11:11:29.344315Z"
        },
        "id": "1Rz82wEs5biZ"
      },
      "source": [
        "def positional_encoding(position, d_model):\n",
        "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                          np.arange(d_model)[np.newaxis, :],\n",
        "                          d_model)\n",
        "\n",
        "  # apply sin to even indices in the array; 2i\n",
        "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "  # apply cos to odd indices in the array; 2i+1\n",
        "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "  pos_encoding = angle_rads[np.newaxis, ...]\n",
        "\n",
        "  return tf.cast(pos_encoding, dtype=tf.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:11:29.349567Z",
          "iopub.status.busy": "2021-08-25T11:11:29.349032Z",
          "iopub.status.idle": "2021-08-25T11:11:29.984839Z",
          "shell.execute_reply": "2021-08-25T11:11:29.985250Z"
        },
        "id": "1kLCla68EloE"
      },
      "source": [
        "n, d = 2048, 512\n",
        "pos_encoding = positional_encoding(n, d)\n",
        "print(pos_encoding.shape)\n",
        "pos_encoding = pos_encoding[0]\n",
        "\n",
        "# Juggle the dimensions for the plot\n",
        "pos_encoding = tf.reshape(pos_encoding, (n, d//2, 2))\n",
        "pos_encoding = tf.transpose(pos_encoding, (2, 1, 0))\n",
        "pos_encoding = tf.reshape(pos_encoding, (d, n))\n",
        "\n",
        "plt.pcolormesh(pos_encoding, cmap='RdBu')\n",
        "plt.ylabel('Depth')\n",
        "plt.xlabel('Position')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_b4ou4TYqUN"
      },
      "source": [
        "## Mặt nạ\n",
        "\n",
        "Che dấu tất cả các token pad trong lô của chuỗi. Nó đảm bảo rằng mô hình không coi padding như đầu vào. Mặt nạ chỉ ra nơi pad giá trị `0` hiện diện: nó sẽ tạo ra `1` ở những địa điểm dó, và `0` ngược lại."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:11:29.990433Z",
          "iopub.status.busy": "2021-08-25T11:11:29.989737Z",
          "iopub.status.idle": "2021-08-25T11:11:29.992074Z",
          "shell.execute_reply": "2021-08-25T11:11:29.991684Z"
        },
        "id": "U2i8-e1s8ti9"
      },
      "source": [
        "def create_padding_mask(seq):\n",
        "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "\n",
        "  # add extra dimensions to add the padding\n",
        "  # to the attention logits.\n",
        "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:11:29.996635Z",
          "iopub.status.busy": "2021-08-25T11:11:29.995794Z",
          "iopub.status.idle": "2021-08-25T11:11:30.000998Z",
          "shell.execute_reply": "2021-08-25T11:11:30.001438Z"
        },
        "id": "A7BYeBCNvi7n"
      },
      "source": [
        "x = tf.constant([[7, 6, 0, 0, 1], [1, 2, 3, 0, 0], [0, 0, 0, 4, 5]])\n",
        "create_padding_mask(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0hzukDBgVom"
      },
      "source": [
        "Mặt nạ nhìn trước được sử dụng để che dấu các token trong tương lai theo một chuỗi. Nói cách khác, mặt nạ cho biết mục nhập nào không nên được sử dụng.\n",
        "\n",
        "Điều này có nghĩa là để dự đoán token thứ ba, chỉ token đầu tiên và thứ hai sẽ được sử dụng. Tương tự như vậy để dự đoán token thứ tư, chỉ token đầu tiên, thứ hai và thứ ba sẽ được sử dụng, v.v."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:11:30.006359Z",
          "iopub.status.busy": "2021-08-25T11:11:30.005562Z",
          "iopub.status.idle": "2021-08-25T11:11:30.007821Z",
          "shell.execute_reply": "2021-08-25T11:11:30.007403Z"
        },
        "id": "dVxS8OPI9uI0"
      },
      "source": [
        "def create_look_ahead_mask(size):\n",
        "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "  return mask  # (seq_len, seq_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:11:30.012804Z",
          "iopub.status.busy": "2021-08-25T11:11:30.011866Z",
          "iopub.status.idle": "2021-08-25T11:11:30.017012Z",
          "shell.execute_reply": "2021-08-25T11:11:30.016534Z"
        },
        "id": "yxKGuXxaBeeE"
      },
      "source": [
        "x = tf.random.uniform((1, 3))\n",
        "temp = create_look_ahead_mask(x.shape[1])\n",
        "temp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xluDl5cXYy4y"
      },
      "source": [
        "## Sự chú ý tích vô hương theo tỷ lệ\n",
        "\n",
        "![scaled_attention](img/scaled_attention.png)\n",
        "\n",
        "Hàm chú ý được dùng bởi transformer lấy 3 đầu vào: Q (query), K (key), V (value). Phương trình được sử dụng để tính toán các trọng số chú ý là:\n",
        "\n",
        "$$\\Large{Attention(Q, K, V) = softmax_k\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right) V} $$\n",
        "\n",
        "Sự chú ý tích vô hướng được chia tỷ lệ bởi một hệ số của căn bậc 2 của độ sâu. Điều này được thực hiện bởi vì các giá trị lớn của độ sâu, tích vô hướng lớn dần theo độ lớn đẩy hàm softmax nơi mà nó có các độ dốc nhỏ dẫn đến một softmax rất khó.\n",
        "\n",
        "Ví dụ, xem xét `Q` và `K` có trung bình là 0 và phương sai là 1. Phép nhân ma trận của chúng sẽ có trung bình 0 và phương sai `dk`. Vì vậy *căn bậc hai của* `dk` được dùng cho chia tỷ lệ, vì vậy bạn có một phương sai phù hợp không phụ thuộc vào giá trị của `dk`. Nếu phương sai quá nhỏ, đầu ra có thể là quá phẳng để tối ưu hiệu quả. Nếu phương sai quá lớn, softmax có thể bảo hoà ở khởi tạo làm nó khó khăn khi học.\n",
        "\n",
        "Mặt nạ được nhân với -1e9 (gần âm vô cùng). Điều này được thực hiện bởi vì mặt nạ được tính tổng với phép nhân ma trận tỷ lệ của Q và K và được áp dụng ngay trước một softmax. Mục tiêu là giảm về 0 (loại bỏ) các ô này, và các đầu vào âm lớn cho softmax là gần không ở đầu ra."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:11:30.023578Z",
          "iopub.status.busy": "2021-08-25T11:11:30.022721Z",
          "iopub.status.idle": "2021-08-25T11:11:30.024582Z",
          "shell.execute_reply": "2021-08-25T11:11:30.025036Z"
        },
        "id": "LazzUq3bJ5SH"
      },
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "  \"\"\"Calculate the attention weights.\n",
        "  q, k, v must have matching leading dimensions.\n",
        "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
        "  The mask has different shapes depending on its type(padding or look ahead)\n",
        "  but it must be broadcastable for addition.\n",
        "\n",
        "  Args:\n",
        "    q: query shape == (..., seq_len_q, depth)\n",
        "    k: key shape == (..., seq_len_k, depth)\n",
        "    v: value shape == (..., seq_len_v, depth_v)\n",
        "    mask: Float tensor with shape broadcastable\n",
        "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
        "\n",
        "  Returns:\n",
        "    output, attention_weights\n",
        "  \"\"\"\n",
        "\n",
        "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "  # scale matmul_qk\n",
        "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "  # add the mask to the scaled tensor.\n",
        "  if mask is not None:\n",
        "    scaled_attention_logits += (mask * -1e9)\n",
        "\n",
        "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
        "  # add up to 1.\n",
        "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
        "\n",
        "  return output, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiqETnhCkoXh"
      },
      "source": [
        "Khi quá trình chuẩn hóa softmax được thực hiện trên K, các giá trị của nó quyết định mức độ quan trọng của Q.\n",
        "\n",
        "Đầu ra đại diện cho phép nhân của trọng số chú ý và véctơ V (giá trị). Điều này đảm bảo rằng các token bạn muốn tập trung vào được giữ nguyên trạng và các token không liên quan sẽ bị loại bỏ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:11:30.029413Z",
          "iopub.status.busy": "2021-08-25T11:11:30.028768Z",
          "iopub.status.idle": "2021-08-25T11:11:30.031002Z",
          "shell.execute_reply": "2021-08-25T11:11:30.030600Z"
        },
        "id": "n90YjClyInFy"
      },
      "source": [
        "def print_out(q, k, v):\n",
        "  temp_out, temp_attn = scaled_dot_product_attention(\n",
        "      q, k, v, None)\n",
        "  print('Attention weights are:')\n",
        "  print(temp_attn)\n",
        "  print('Output is:')\n",
        "  print(temp_out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:11:30.036497Z",
          "iopub.status.busy": "2021-08-25T11:11:30.035971Z",
          "iopub.status.idle": "2021-08-25T11:11:30.403923Z",
          "shell.execute_reply": "2021-08-25T11:11:30.404265Z"
        },
        "id": "yAzUAf2DPlNt"
      },
      "source": [
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "temp_k = tf.constant([[10, 0, 0],\n",
        "                      [0, 10, 0],\n",
        "                      [0, 0, 10],\n",
        "                      [0, 0, 10]], dtype=tf.float32)  # (4, 3)\n",
        "\n",
        "temp_v = tf.constant([[1, 0],\n",
        "                      [10, 0],\n",
        "                      [100, 5],\n",
        "                      [1000, 6]], dtype=tf.float32)  # (4, 2)\n",
        "\n",
        "# This `query` aligns with the second `key`,\n",
        "# so the second `value` is returned.\n",
        "temp_q = tf.constant([[0, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
        "print_out(temp_q, temp_k, temp_v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:11:30.409230Z",
          "iopub.status.busy": "2021-08-25T11:11:30.408646Z",
          "iopub.status.idle": "2021-08-25T11:11:30.412510Z",
          "shell.execute_reply": "2021-08-25T11:11:30.412125Z"
        },
        "id": "zg6k-fGhgXra"
      },
      "source": [
        "# This query aligns with a repeated key (third and fourth),\n",
        "# so all associated values get averaged.\n",
        "temp_q = tf.constant([[0, 0, 10]], dtype=tf.float32)  # (1, 3)\n",
        "print_out(temp_q, temp_k, temp_v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:11:30.416804Z",
          "iopub.status.busy": "2021-08-25T11:11:30.416209Z",
          "iopub.status.idle": "2021-08-25T11:11:30.420054Z",
          "shell.execute_reply": "2021-08-25T11:11:30.420389Z"
        },
        "id": "UAq3YOzUgXhb"
      },
      "source": [
        "# This query aligns equally with the first and second key,\n",
        "# so their values get averaged.\n",
        "temp_q = tf.constant([[10, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
        "print_out(temp_q, temp_k, temp_v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOz-4_XIhaTP"
      },
      "source": [
        "Truyền tất cả các truy vấn cùng lúc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:11:30.424699Z",
          "iopub.status.busy": "2021-08-25T11:11:30.424124Z",
          "iopub.status.idle": "2021-08-25T11:11:30.427658Z",
          "shell.execute_reply": "2021-08-25T11:11:30.427997Z"
        },
        "id": "6dlU8Tm-hYrF"
      },
      "source": [
        "temp_q = tf.constant([[0, 0, 10],\n",
        "                      [0, 10, 0],\n",
        "                      [10, 10, 0]], dtype=tf.float32)  # (3, 3)\n",
        "print_out(temp_q, temp_k, temp_v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmzGPEy64qmA"
      },
      "source": [
        "## Sự chú ý từ nhiều phía\n",
        "\n",
        "![multi_head_attention](img/multi_head_attention.png)\n",
        "\n",
        "Sự chú ý từ nhiều phía bao gồm bốn phần:\n",
        "\n",
        "*    Các lớp tuyến tính.\n",
        "\n",
        "*    Sự chú ý nhân vô hướng theo tỷ lệ.\n",
        "\n",
        "*    Lớp tuyến tính cuối cùng.\n",
        "\n",
        "Mỗi khối chú ý nhiều phía nhận được ba đầu vào: Q (truy vấn), K (khóa), V (giá trị). Chúng được đưa qua các lớp tuyến tính (Dense) trước hàm chú ý nhiều phía.\n",
        "\n",
        "Trong sơ đồ trên `(K, Q, V)` được truyền qua các lớp tuyến tính riêng lẽ (`Dense`) cho mỗi phía chú ý. Để đơn giản/hiệu quả vào mã bên dưới triển khai cái này sử dụng một lớp dense duy nhất với `num_heads` lần như nhiều kết quả đầu ra. Kết quả được sắp xếp lại để một hình dạng của `(batch, num_heads, ...)` trước khi áp dụng hàm chú ý.\n",
        "\n",
        "Chức năng `scaled_dot_product_attention` được định nghĩa ở trên được áp dụng trong một lời gọi duy nhất, phát sóng cho hiệu quả. Trong bước chú ý phải sử dụng một mặt nạ thích hợp. Kết quả sự chú ý cho mỗi phía sau đó được nối (sử dụng `tf.transpose`, và `tf.reshape`) và đưa qua một lớp Dense cuối cùng.\n",
        "\n",
        "Thay vì một phía chú ý duy nhất, Q, K và V được chia thành nhiều phía vì nó cho phép mô hình cùng tham gia vào thông tin từ các không gian con biểu diễn khác nhau ở các vị trí khác nhau. Sau khi tách, mỗi phía có số chiều được giảm, do đó, tổng chi phí tính toán giống như sự chú ý của phía duy nhất với kích thước đầy đủ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:11:30.436550Z",
          "iopub.status.busy": "2021-08-25T11:11:30.435988Z",
          "iopub.status.idle": "2021-08-25T11:11:30.437551Z",
          "shell.execute_reply": "2021-08-25T11:11:30.437867Z"
        },
        "id": "BSV3PPKsYecw"
      },
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0\n",
        "\n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    self.wq = tf.keras.layers.Dense(d_model)\n",
        "    self.wk = tf.keras.layers.Dense(d_model)\n",
        "    self.wv = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "  def split_heads(self, x, batch_size):\n",
        "    \"\"\"Split the last dimension into (num_heads, depth).\n",
        "    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
        "    \"\"\"\n",
        "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "  def call(self, v, k, q, mask):\n",
        "    batch_size = tf.shape(q)[0]\n",
        "\n",
        "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
        "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
        "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
        "\n",
        "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
        "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
        "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
        "\n",
        "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
        "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "        q, k, v, mask)\n",
        "\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
        "\n",
        "    concat_attention = tf.reshape(scaled_attention,\n",
        "                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "    return output, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0D8FJue5lDyZ"
      },
      "source": [
        "Tạo một lớp `MultiHeadAttention` để thử kỹ càng. Tại mỗi vị trí trong chuỗi, `y`, `MultiHeadAttention` chạy hết 8 phía chú ý trên tất cả các vị trí khác nhau trong chuỗi, trả về một véctơ với cùng chiều dài ở mỗi vị trí."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:11:30.441939Z",
          "iopub.status.busy": "2021-08-25T11:11:30.441430Z",
          "iopub.status.idle": "2021-08-25T11:11:30.464381Z",
          "shell.execute_reply": "2021-08-25T11:11:30.463964Z"
        },
        "id": "Hu94p-_-2_BX"
      },
      "source": [
        "temp_mha = MultiHeadAttention(d_model=512, num_heads=8)\n",
        "y = tf.random.uniform((1, 60, 512))  # (batch_size, encoder_sequence, d_model)\n",
        "out, attn = temp_mha(y, k=y, q=y, mask=None)\n",
        "out.shape, attn.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdDqGayx67vv"
      },
      "source": [
        "## Mạng truyền thẳng điểm định tính\n",
        "\n",
        "Mạng truyền thẳng định tính bao gồm hai lớp kết nối đầy đủ với một kích hoạt ReLU ở giữa."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:11:30.468352Z",
          "iopub.status.busy": "2021-08-25T11:11:30.467812Z",
          "iopub.status.idle": "2021-08-25T11:11:30.469623Z",
          "shell.execute_reply": "2021-08-25T11:11:30.469937Z"
        },
        "id": "ET7xLt0yCT6Z"
      },
      "source": [
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "  return tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
        "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
        "  ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:11:30.475096Z",
          "iopub.status.busy": "2021-08-25T11:11:30.474588Z",
          "iopub.status.idle": "2021-08-25T11:11:30.496740Z",
          "shell.execute_reply": "2021-08-25T11:11:30.496346Z"
        },
        "id": "mytb1lPyOHLB"
      },
      "source": [
        "sample_ffn = point_wise_feed_forward_network(512, 2048)\n",
        "sample_ffn(tf.random.uniform((64, 50, 512))).shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e7hKcxn6-zd"
      },
      "source": [
        "## Mã hoá và giải mã\n",
        "\n",
        "![transformer](img/transformer.png)\n",
        "\n",
        "Mô hình transformer theo sau cùng mẫu chung như một [chuối sang chuỗi với mô hình đáng chú ý](https://www.tensorflow.org/text/tutorials/nmt_with_attention.ipynb) tiêu chuẩn. \n",
        "\n",
        "* Câu đầu vào được chuyển qua `N` lớp mã hoá tạo một đầu ra cho mỗi token trong chuỗi.\n",
        "\n",
        "* Giải mã tham gia vào đầu ra của mã hoá với đầu vào của nó (tự chú ý) để dự đoán từ tiếp theo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFv-FNYUmvpn"
      },
      "source": [
        "### Lớp mã hóa\n",
        "\n",
        "Mỗi lớp mã hóa bao gồm các lớp con:\n",
        "\n",
        "1. Chú ý nhiều phía (với mặt nạ đệm)\n",
        "\n",
        "2. Các mạng truyền thẳng định tính\n",
        "\n",
        "Mỗi lớp con này có một kết nối dư xung quanh nó, theo sau là chuẩn hóa lớp. Các kết nối dư giúp tránh vấn đề độ dốc biến mất trong các mạng sâu.\n",
        "\n",
        "Đầu ra của mỗi lớp con là `LayerNorm(x + Sublayer(x))`. Chuẩn hóa được thực hiện trên trục `d_model` (cuối cùng). Có N lớp mã hóa trong transformer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:11:30.504154Z",
          "iopub.status.busy": "2021-08-25T11:11:30.503335Z",
          "iopub.status.idle": "2021-08-25T11:11:30.505285Z",
          "shell.execute_reply": "2021-08-25T11:11:30.505623Z"
        },
        "id": "ncyS-Ms3i2x_"
      },
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(EncoderLayer, self).__init__()\n",
        "\n",
        "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "  def call(self, x, training, mask):\n",
        "\n",
        "    attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
        "    attn_output = self.dropout1(attn_output, training=training)\n",
        "    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
        "    ffn_output = self.dropout2(ffn_output, training=training)\n",
        "    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    return out2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:11:30.514147Z",
          "iopub.status.busy": "2021-08-25T11:11:30.513559Z",
          "iopub.status.idle": "2021-08-25T11:11:30.553909Z",
          "shell.execute_reply": "2021-08-25T11:11:30.553400Z"
        },
        "id": "AzZRXdO0mI48"
      },
      "source": [
        "sample_encoder_layer = EncoderLayer(512, 8, 2048)\n",
        "\n",
        "sample_encoder_layer_output = sample_encoder_layer(\n",
        "    tf.random.uniform((64, 43, 512)), False, None)\n",
        "\n",
        "sample_encoder_layer_output.shape  # (batch_size, input_seq_len, d_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LO_48Owmx_o"
      },
      "source": [
        "### Lớp giải mã\n",
        "\n",
        "Mỗi lớp giải mã bao gồm các lớp con:\n",
        "\n",
        "1. Mặt nạ chú ý nhiều phía (với mặt nạ nhìn trước và mặt nạ đệm)\n",
        "\n",
        "2. Chú ý nhiều phía (có mặt nạ đệm). V (giá trị) và K (key) nhận được *đầu ra bộ mã hóa* là các đầu vào. Q (query) nhận được *đầu ra từ lớp con chú ý nhiều phía được che giấu*.\n",
        "\n",
        "3. Các mạng truyền thẳng định tính\n",
        "\n",
        "Mỗi lớp con này có một kết nối dư xung quanh nó, theo sau là chuẩn hóa lớp. Đầu ra của mỗi lớp con là `LayerNorm(x + Sublayer(x))`. Chuẩn hóa được thực hiện trên trục `d_model` (cuối cùng).\n",
        "\n",
        "Có N lớp giải mã trong transformer.\n",
        "\n",
        "Khi Q nhận đầu ra từ khối chú ý đầu tiên của bộ giải mã và K nhận đầu ra của bộ mã hóa, trọng số chú ý thể hiện sự quan trọng đối với đầu vào của bộ giải mã dựa trên đầu ra của bộ mã hóa. Nói cách khác, bộ giải mã dự đoán token tiếp theo bằng cách xem đầu ra của bộ mã hóa và tự tham gia vào đầu ra của chính nó. Xem phần minh họa ở trên trong phần *sự chú ý tích vô phương theo tỷ lệ*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:11:30.561487Z",
          "iopub.status.busy": "2021-08-25T11:11:30.560942Z",
          "iopub.status.idle": "2021-08-25T11:11:30.562957Z",
          "shell.execute_reply": "2021-08-25T11:11:30.563279Z"
        },
        "id": "9SoX0-vd1hue"
      },
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(DecoderLayer, self).__init__()\n",
        "\n",
        "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "  def call(self, x, enc_output, training,\n",
        "           look_ahead_mask, padding_mask):\n",
        "    # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
        "    attn1 = self.dropout1(attn1, training=training)\n",
        "    out1 = self.layernorm1(attn1 + x)\n",
        "\n",
        "    attn2, attn_weights_block2 = self.mha2(\n",
        "        enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
        "    attn2 = self.dropout2(attn2, training=training)\n",
        "    out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "    ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
        "    ffn_output = self.dropout3(ffn_output, training=training)\n",
        "    out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "    return out3, attn_weights_block1, attn_weights_block2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:11:30.573952Z",
          "iopub.status.busy": "2021-08-25T11:11:30.573399Z",
          "iopub.status.idle": "2021-08-25T11:11:30.623958Z",
          "shell.execute_reply": "2021-08-25T11:11:30.623533Z"
        },
        "id": "Ne2Bqx8k71l0"
      },
      "source": [
        "sample_decoder_layer = DecoderLayer(512, 8, 2048)\n",
        "\n",
        "sample_decoder_layer_output, _, _ = sample_decoder_layer(\n",
        "    tf.random.uniform((64, 50, 512)), sample_encoder_layer_output,\n",
        "    False, None, None)\n",
        "\n",
        "sample_decoder_layer_output.shape  # (batch_size, target_seq_len, d_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SE1H51Ajm0q1"
      },
      "source": [
        "### Mã hoá\n",
        "\n",
        "`Encoder` bao gồm:\n",
        "\n",
        "1. Nhúng đầu vào\n",
        "\n",
        "2. Mã hóa vị trí\n",
        "\n",
        "3. N lớp mã hóa\n",
        "\n",
        "Đầu vào được đưa qua một phép nhúng được tổng hợp bằng mã hóa vị trí. Đầu ra của tổng hợp này là đầu vào cho các lớp mã hóa. Đầu ra của bộ mã hóa là đầu vào cho bộ giải mã."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:11:30.630988Z",
          "iopub.status.busy": "2021-08-25T11:11:30.630463Z",
          "iopub.status.idle": "2021-08-25T11:11:30.632377Z",
          "shell.execute_reply": "2021-08-25T11:11:30.632699Z"
        },
        "id": "jpEox7gJ8FCI"
      },
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
        "               maximum_position_encoding, rate=0.1):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(maximum_position_encoding,\n",
        "                                            self.d_model)\n",
        "\n",
        "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate)\n",
        "                       for _ in range(num_layers)]\n",
        "\n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "  def call(self, x, training, mask):\n",
        "\n",
        "    seq_len = tf.shape(x)[1]\n",
        "\n",
        "    # adding embedding and position encoding.\n",
        "    x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "    x = self.dropout(x, training=training)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x = self.enc_layers[i](x, training, mask)\n",
        "\n",
        "    return x  # (batch_size, input_seq_len, d_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:11:30.638724Z",
          "iopub.status.busy": "2021-08-25T11:11:30.638201Z",
          "iopub.status.idle": "2021-08-25T11:11:30.892503Z",
          "shell.execute_reply": "2021-08-25T11:11:30.892879Z"
        },
        "id": "8QG9nueFQKXx"
      },
      "source": [
        "sample_encoder = Encoder(num_layers=2, d_model=512, num_heads=8,\n",
        "                         dff=2048, input_vocab_size=8500,\n",
        "                         maximum_position_encoding=10000)\n",
        "temp_input = tf.random.uniform((64, 62), dtype=tf.int64, minval=0, maxval=200)\n",
        "\n",
        "sample_encoder_output = sample_encoder(temp_input, training=False, mask=None)\n",
        "\n",
        "print(sample_encoder_output.shape)  # (batch_size, input_seq_len, d_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-uO6ls8m2O5"
      },
      "source": [
        "### Giải mã\n",
        "\n",
        "`Decoder` bao gồm:\n",
        "\n",
        "1. Nhúng đầu ra\n",
        "\n",
        "2. Mã hóa vị trí\n",
        "\n",
        "3. N lớp giải mã\n",
        "\n",
        "Mục tiêu được đưa qua một phép nhúng được tổng hợp bằng mã hóa vị trí. Đầu ra của phép tổng hợp này là đầu vào cho các lớp giải mã. Đầu ra của bộ giải mã là đầu vào của lớp tuyến tính cuối cùng."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:11:30.900884Z",
          "iopub.status.busy": "2021-08-25T11:11:30.900206Z",
          "iopub.status.idle": "2021-08-25T11:11:30.903335Z",
          "shell.execute_reply": "2021-08-25T11:11:30.902907Z"
        },
        "id": "d5_d5-PLQXwY"
      },
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
        "               maximum_position_encoding, rate=0.1):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
        "\n",
        "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate)\n",
        "                       for _ in range(num_layers)]\n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "  def call(self, x, enc_output, training,\n",
        "           look_ahead_mask, padding_mask):\n",
        "\n",
        "    seq_len = tf.shape(x)[1]\n",
        "    attention_weights = {}\n",
        "\n",
        "    x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "    x = self.dropout(x, training=training)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
        "                                             look_ahead_mask, padding_mask)\n",
        "\n",
        "      attention_weights[f'decoder_layer{i+1}_block1'] = block1\n",
        "      attention_weights[f'decoder_layer{i+1}_block2'] = block2\n",
        "\n",
        "    # x.shape == (batch_size, target_seq_len, d_model)\n",
        "    return x, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:11:30.908973Z",
          "iopub.status.busy": "2021-08-25T11:11:30.908391Z",
          "iopub.status.idle": "2021-08-25T11:11:31.102106Z",
          "shell.execute_reply": "2021-08-25T11:11:31.101679Z"
        },
        "id": "a1jXoAMRZyvu"
      },
      "source": [
        "sample_decoder = Decoder(num_layers=2, d_model=512, num_heads=8,\n",
        "                         dff=2048, target_vocab_size=8000,\n",
        "                         maximum_position_encoding=5000)\n",
        "temp_input = tf.random.uniform((64, 26), dtype=tf.int64, minval=0, maxval=200)\n",
        "\n",
        "output, attn = sample_decoder(temp_input,\n",
        "                              enc_output=sample_encoder_output,\n",
        "                              training=False,\n",
        "                              look_ahead_mask=None,\n",
        "                              padding_mask=None)\n",
        "\n",
        "output.shape, attn['decoder_layer2_block2'].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y54xnJnuYgJ7"
      },
      "source": [
        "## Tạo Transformer\n",
        "\n",
        "Transformer bao gồm bộ mã hóa, bộ giải mã và một lớp tuyến tính cuối cùng. Đầu ra của bộ giải mã là đầu vào của lớp tuyến tính và đầu ra của nó được trả về."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:11:31.110197Z",
          "iopub.status.busy": "2021-08-25T11:11:31.109573Z",
          "iopub.status.idle": "2021-08-25T11:11:31.112051Z",
          "shell.execute_reply": "2021-08-25T11:11:31.111606Z"
        },
        "id": "PED3bIpOYkBu"
      },
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
        "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
        "    super().__init__()\n",
        "    self.encoder = Encoder(num_layers, d_model, num_heads, dff,\n",
        "                             input_vocab_size, pe_input, rate)\n",
        "\n",
        "    self.decoder = Decoder(num_layers, d_model, num_heads, dff,\n",
        "                           target_vocab_size, pe_target, rate)\n",
        "\n",
        "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "\n",
        "  def call(self, inputs, training):\n",
        "    # Keras models prefer if you pass all your inputs in the first argument\n",
        "    inp, tar = inputs\n",
        "\n",
        "    enc_padding_mask, look_ahead_mask, dec_padding_mask = self.create_masks(inp, tar)\n",
        "\n",
        "    enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
        "\n",
        "    # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
        "    dec_output, attention_weights = self.decoder(\n",
        "        tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
        "\n",
        "    final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
        "\n",
        "    return final_output, attention_weights\n",
        "\n",
        "  def create_masks(self, inp, tar):\n",
        "    # Encoder padding mask\n",
        "    enc_padding_mask = create_padding_mask(inp)\n",
        "\n",
        "    # Used in the 2nd attention block in the decoder.\n",
        "    # This padding mask is used to mask the encoder outputs.\n",
        "    dec_padding_mask = create_padding_mask(inp)\n",
        "\n",
        "    # Used in the 1st attention block in the decoder.\n",
        "    # It is used to pad and mask future tokens in the input received by\n",
        "    # the decoder.\n",
        "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
        "    dec_target_padding_mask = create_padding_mask(tar)\n",
        "    look_ahead_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "\n",
        "    return enc_padding_mask, look_ahead_mask, dec_padding_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:11:31.117919Z",
          "iopub.status.busy": "2021-08-25T11:11:31.117300Z",
          "iopub.status.idle": "2021-08-25T11:11:31.560028Z",
          "shell.execute_reply": "2021-08-25T11:11:31.559558Z"
        },
        "id": "tJ4fbQcIkHW1"
      },
      "source": [
        "sample_transformer = Transformer(\n",
        "    num_layers=2, d_model=512, num_heads=8, dff=2048,\n",
        "    input_vocab_size=8500, target_vocab_size=8000,\n",
        "    pe_input=10000, pe_target=6000)\n",
        "\n",
        "temp_input = tf.random.uniform((64, 38), dtype=tf.int64, minval=0, maxval=200)\n",
        "temp_target = tf.random.uniform((64, 36), dtype=tf.int64, minval=0, maxval=200)\n",
        "\n",
        "fn_out, _ = sample_transformer([temp_input, temp_target], training=False)\n",
        "\n",
        "fn_out.shape  # (batch_size, tar_seq_len, target_vocab_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsINyf1VEQLC"
      },
      "source": [
        "## Đặt siêu tham số\n",
        "\n",
        "Để giữ cho ví dụ này nhỏ và tương đối nhanh, các giá trị cho `num_layers, d_model, dff` đã được giảm.\n",
        "\n",
        "Mô hình cơ sở được mô tả trong [bài](https://arxiv.org/abs/1706.03762) sử dụng: `num_layers=6, d_model=512, dff=2048`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:11:31.564217Z",
          "iopub.status.busy": "2021-08-25T11:11:31.563682Z",
          "iopub.status.idle": "2021-08-25T11:11:31.565481Z",
          "shell.execute_reply": "2021-08-25T11:11:31.565815Z"
        },
        "id": "lnJn5SLA2ahP"
      },
      "source": [
        "num_layers = 4\n",
        "d_model = 128\n",
        "dff = 512\n",
        "num_heads = 8\n",
        "dropout_rate = 0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYEGhEOtzn5W"
      },
      "source": [
        "## Bộ tối ưu hoá\n",
        "\n",
        "Sử dụng bộ tối ưu Adam với một bộ lên lịch  tỷ lệ học tùy chỉnh theo công thức trong [bài](https://arxiv.org/abs/1706.03762).\n",
        "\n",
        "$$\\Large{lrate = d_{model}^{-0.5} * \\min(step{\\_}num^{-0.5}, step{\\_}num \\cdot warmup{\\_}steps^{-1.5})}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:11:31.570971Z",
          "iopub.status.busy": "2021-08-25T11:11:31.570438Z",
          "iopub.status.idle": "2021-08-25T11:11:31.572287Z",
          "shell.execute_reply": "2021-08-25T11:11:31.572643Z"
        },
        "id": "iYQdOO1axwEI"
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:11:31.576505Z",
          "iopub.status.busy": "2021-08-25T11:11:31.575987Z",
          "iopub.status.idle": "2021-08-25T11:11:31.578712Z",
          "shell.execute_reply": "2021-08-25T11:11:31.578270Z"
        },
        "id": "7r4scdulztRx"
      },
      "source": [
        "learning_rate = CustomSchedule(d_model)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
        "                                     epsilon=1e-9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:11:31.582872Z",
          "iopub.status.busy": "2021-08-25T11:11:31.582294Z",
          "iopub.status.idle": "2021-08-25T11:11:31.715560Z",
          "shell.execute_reply": "2021-08-25T11:11:31.715129Z"
        },
        "id": "f33ZCgvHpPdG"
      },
      "source": [
        "temp_learning_rate_schedule = CustomSchedule(d_model)\n",
        "\n",
        "plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.xlabel(\"Train Step\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgkDE7hzo8r5"
      },
      "source": [
        "## Mất mát và chỉ số đo lường\n",
        "\n",
        "Vì các chuỗi mục tiêu được đệm, điều quan trọng là phải áp dụng mặt nạ đệm khi tính toán mất mát."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:11:31.719517Z",
          "iopub.status.busy": "2021-08-25T11:11:31.718956Z",
          "iopub.status.idle": "2021-08-25T11:11:31.721390Z",
          "shell.execute_reply": "2021-08-25T11:11:31.720917Z"
        },
        "id": "MlhsJMm0TW_B"
      },
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:11:31.727222Z",
          "iopub.status.busy": "2021-08-25T11:11:31.726646Z",
          "iopub.status.idle": "2021-08-25T11:11:31.728848Z",
          "shell.execute_reply": "2021-08-25T11:11:31.728446Z"
        },
        "id": "67oqVHiT0Eiu"
      },
      "source": [
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
        "\n",
        "\n",
        "def accuracy_function(real, pred):\n",
        "  accuracies = tf.equal(real, tf.argmax(pred, axis=2))\n",
        "\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  accuracies = tf.math.logical_and(mask, accuracies)\n",
        "\n",
        "  accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
        "  mask = tf.cast(mask, dtype=tf.float32)\n",
        "  return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:11:31.734983Z",
          "iopub.status.busy": "2021-08-25T11:11:31.734362Z",
          "iopub.status.idle": "2021-08-25T11:11:31.740258Z",
          "shell.execute_reply": "2021-08-25T11:11:31.739859Z"
        },
        "id": "phlyxMnm-Tpx"
      },
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeHumfr7zmMa"
      },
      "source": [
        "## Huấn luyện và điểm kiểm tra"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:11:31.745734Z",
          "iopub.status.busy": "2021-08-25T11:11:31.745204Z",
          "iopub.status.idle": "2021-08-25T11:11:31.840746Z",
          "shell.execute_reply": "2021-08-25T11:11:31.840234Z"
        },
        "id": "UiysUa--4tOU"
      },
      "source": [
        "transformer = Transformer(\n",
        "    num_layers=num_layers,\n",
        "    d_model=d_model,\n",
        "    num_heads=num_heads,\n",
        "    dff=dff,\n",
        "    input_vocab_size=tokenizers.pt.get_vocab_size().numpy(),\n",
        "    target_vocab_size=tokenizers.en.get_vocab_size().numpy(),\n",
        "    pe_input=1000,\n",
        "    pe_target=1000,\n",
        "    rate=dropout_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fzuf06YZp66w"
      },
      "source": [
        "Tạo đường dẫn điểm kiểm tra và trình quản lý điểm kiểm tra. Điều này sẽ được sử dụng để lưu các điểm kiểm tra mỗi `n` epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:11:31.846066Z",
          "iopub.status.busy": "2021-08-25T11:11:31.845451Z",
          "iopub.status.idle": "2021-08-25T11:11:31.847115Z",
          "shell.execute_reply": "2021-08-25T11:11:31.847467Z"
        },
        "id": "hNhuYfllndLZ"
      },
      "source": [
        "checkpoint_path = \"./checkpoints/train\"\n",
        "\n",
        "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
        "                           optimizer=optimizer)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
        "\n",
        "# if a checkpoint exists, restore the latest checkpoint.\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "  print('Latest checkpoint restored!!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Di_Yaa1gf9r"
      },
      "source": [
        "Mục tiêu được chia thành `tar_inp` và `tar_real`. `tar_inp` được chuyển đi như một đầu vào cho bộ giải mã. `tar_real` là cùng một đầu vào được dịch chuyển bởi 1: Tại mỗi vị trí trong `tar_input`, `tar_real` chứa token kế tiếp cần được dự đoán.\n",
        "\n",
        "Ví dụ, `sentence` = \"SOS A lion in the jungle is sleeping EOS\"\n",
        "\n",
        "`tar_inp` =  \"SOS A lion in the jungle is sleeping\"\n",
        "\n",
        "`tar_real` = \"A lion in the jungle is sleeping EOS\"\n",
        "\n",
        "Transformer là một mô hình tự động hồi quy: nó đưa ra dự đoán từng phần một và sử dụng kết quả đầu ra của nó để quyết định phải làm gì tiếp theo.\n",
        "\n",
        "Trong huấn luyện ví dụ này sử dụng teacher-forcing (như trong hướng dẫn [sinh văn bản](https://www.tensorflow.org/text/tutorials/text_generation)). Giáo viên buộc phải chuyển đầu ra thực sự cho bước thời gian tiếp theo bất kể mô hình dự đoán những gì ở bước thời gian hiện tại.\n",
        "\n",
        "Khi transformer dự đoán mỗi token, *tự chú ý* cho phép nó để nhìn vào các token trước đó trong chuỗi đầu vào tốt hơn dự đoán token tiếp theo.\n",
        "\n",
        "Để ngăn mô hình nhìn trộm đầu ra dự kiến, mô hình sử dụng mặt nạ nhìn trước."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:11:31.851027Z",
          "iopub.status.busy": "2021-08-25T11:11:31.850475Z",
          "iopub.status.idle": "2021-08-25T11:11:31.852167Z",
          "shell.execute_reply": "2021-08-25T11:11:31.852503Z"
        },
        "id": "LKpoA6q1sJFj"
      },
      "source": [
        "EPOCHS = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:11:31.858607Z",
          "iopub.status.busy": "2021-08-25T11:11:31.858001Z",
          "iopub.status.idle": "2021-08-25T11:11:31.859617Z",
          "shell.execute_reply": "2021-08-25T11:11:31.859941Z"
        },
        "id": "iJwmp9OE29oj"
      },
      "source": [
        "# The @tf.function trace-compiles train_step into a TF graph for faster\n",
        "# execution. The function specializes to the precise shape of the argument\n",
        "# tensors. To avoid re-tracing due to the variable sequence lengths or variable\n",
        "# batch sizes (the last batch is smaller), use input_signature to specify\n",
        "# more generic shapes.\n",
        "\n",
        "train_step_signature = [\n",
        "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
        "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
        "]\n",
        "\n",
        "\n",
        "@tf.function(input_signature=train_step_signature)\n",
        "def train_step(inp, tar):\n",
        "  tar_inp = tar[:, :-1]\n",
        "  tar_real = tar[:, 1:]\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions, _ = transformer([inp, tar_inp],\n",
        "                                 training = True)\n",
        "    loss = loss_function(tar_real, predictions)\n",
        "\n",
        "  gradients = tape.gradient(loss, transformer.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "\n",
        "  train_loss(loss)\n",
        "  train_accuracy(accuracy_function(tar_real, predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qM2PDWGDJ_8V"
      },
      "source": [
        "Tiếng Bồ Đào Nha được sử dụng làm ngôn ngữ đầu vào và tiếng Anh là ngôn ngữ đích."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:11:31.865318Z",
          "iopub.status.busy": "2021-08-25T11:11:31.864564Z",
          "iopub.status.idle": "2021-08-25T11:26:47.809623Z",
          "shell.execute_reply": "2021-08-25T11:26:47.809152Z"
        },
        "id": "bbvmaKNiznHZ"
      },
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  train_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "\n",
        "  # inp -> portuguese, tar -> english\n",
        "  for (batch, (inp, tar)) in enumerate(train_batches):\n",
        "    train_step(inp, tar)\n",
        "\n",
        "    if batch % 50 == 0:\n",
        "      print(f'Epoch {epoch + 1} Batch {batch} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
        "\n",
        "  if (epoch + 1) % 5 == 0:\n",
        "    ckpt_save_path = ckpt_manager.save()\n",
        "    print(f'Saving checkpoint for epoch {epoch+1} at {ckpt_save_path}')\n",
        "\n",
        "  print(f'Epoch {epoch + 1} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
        "\n",
        "  print(f'Time taken for 1 epoch: {time.time() - start:.2f} secs\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfcsSWswSdGV"
      },
      "source": [
        "### Chạy suy luận\n",
        "\n",
        "Các bước sau được sử dụng để suy luận:\n",
        "\n",
        "* Mã hóa các câu đầu vào bằng cách sử dụng tokenizer Bồ Đào Nha (`tokenizers.pt`). Đây là đầu vào của bộ mã hóa.\n",
        "\n",
        "* Các đầu vào bộ giải mã được khởi tạo với token `[START]`.\n",
        "\n",
        "* Tính toán mặt nạ đệm và mặt nạ nhìn trước.\n",
        "\n",
        "* Các `decoder` sau đó các kết quả đầu ra dự đoán bằng cách nhìn vào `encoder output` và đầu ra riêng (tự chú ý) của nó.\n",
        "\n",
        "* Nối token dự đoán với đầu vào của bộ giải mã và chuyển nó đến bộ giải mã.\n",
        "\n",
        "* Trong cách tiếp cận này, bộ giải mã dự đoán token tiếp theo dựa trên các token trước đó nó đã dự đoán.\n",
        "\n",
        "Lưu ý: Mô hình này được tối ưu hóa cho *hiệu quả huấn luyện* và làm cho một dự đoán tiếp theo cho mỗi *token* trong đầu ra cùng một lúc. Điều này là thừa trong quá trình suy luận và chỉ dự đoán cuối cùng được sử dụng. Mô hình này có thể được thực hiện hiệu quả hơn đối với kết luận nếu bạn chỉ tính toán dự đoán trước khi chạy ở chế độ suy luận (`training=False`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:26:47.820518Z",
          "iopub.status.busy": "2021-08-25T11:26:47.819906Z",
          "iopub.status.idle": "2021-08-25T11:26:47.821685Z",
          "shell.execute_reply": "2021-08-25T11:26:47.822054Z"
        },
        "id": "5buvMlnvyrFm"
      },
      "source": [
        "class Translator(tf.Module):\n",
        "  def __init__(self, tokenizers, transformer):\n",
        "    self.tokenizers = tokenizers\n",
        "    self.transformer = transformer\n",
        "\n",
        "  def __call__(self, sentence, max_length=20):\n",
        "    # input sentence is portuguese, hence adding the start and end token\n",
        "    assert isinstance(sentence, tf.Tensor)\n",
        "    if len(sentence.shape) == 0:\n",
        "      sentence = sentence[tf.newaxis]\n",
        "\n",
        "    sentence = self.tokenizers.pt.tokenize(sentence).to_tensor()\n",
        "    \n",
        "    encoder_input = sentence\n",
        "\n",
        "    # as the target is english, the first token to the transformer should be the\n",
        "    # english start token.\n",
        "    start_end = self.tokenizers.en.tokenize([''])[0]\n",
        "    start = start_end[0][tf.newaxis]\n",
        "    end = start_end[1][tf.newaxis]\n",
        "\n",
        "    # `tf.TensorArray` is required here (instead of a python list) so that the\n",
        "    # dynamic-loop can be traced by `tf.function`.\n",
        "    output_array = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)\n",
        "    output_array = output_array.write(0, start)\n",
        "    \n",
        "    for i in tf.range(max_length):\n",
        "      output = tf.transpose(output_array.stack())\n",
        "      predictions, _ = self.transformer([encoder_input, output], training=False)\n",
        "      \n",
        "      # select the last token from the seq_len dimension\n",
        "      predictions = predictions[:, -1:, :]  # (batch_size, 1, vocab_size)\n",
        "\n",
        "      predicted_id = tf.argmax(predictions, axis=-1)\n",
        "\n",
        "      # concatentate the predicted_id to the output which is given to the decoder\n",
        "      # as its input.\n",
        "      output_array = output_array.write(i+1, predicted_id[0])\n",
        "\n",
        "      if predicted_id == end:\n",
        "        break\n",
        "\n",
        "    output = tf.transpose(output_array.stack())\n",
        "    # output.shape (1, tokens)\n",
        "    text = tokenizers.en.detokenize(output)[0]  # shape: ()\n",
        "\n",
        "    tokens = tokenizers.en.lookup(output)[0]\n",
        "\n",
        "    # `tf.function` prevents us from using the attention_weights that were\n",
        "    # calculated on the last iteration of the loop. So recalculate them outside\n",
        "    # the loop.\n",
        "    _, attention_weights = self.transformer([encoder_input, output[:,:-1]], training=False)\n",
        "\n",
        "    return text, tokens, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofUWszmY3szZ"
      },
      "source": [
        "Tạo một thể hiện của này lớp `Translator`, và thử nó ra một vài lần:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:26:47.826897Z",
          "iopub.status.busy": "2021-08-25T11:26:47.826210Z",
          "iopub.status.idle": "2021-08-25T11:26:47.828701Z",
          "shell.execute_reply": "2021-08-25T11:26:47.828137Z"
        },
        "id": "4OR2D4EXeIRY"
      },
      "source": [
        "translator = Translator(tokenizers, transformer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:26:47.833332Z",
          "iopub.status.busy": "2021-08-25T11:26:47.832707Z",
          "iopub.status.idle": "2021-08-25T11:26:47.835221Z",
          "shell.execute_reply": "2021-08-25T11:26:47.834678Z"
        },
        "id": "lU2_yG_vBGza"
      },
      "source": [
        "def print_translation(sentence, tokens, ground_truth):\n",
        "  print(f'{\"Input:\":15s}: {sentence}')\n",
        "  print(f'{\"Prediction\":15s}: {tokens.numpy().decode(\"utf-8\")}')\n",
        "  print(f'{\"Ground truth\":15s}: {ground_truth}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:26:47.839906Z",
          "iopub.status.busy": "2021-08-25T11:26:47.839282Z",
          "iopub.status.idle": "2021-08-25T11:26:49.747370Z",
          "shell.execute_reply": "2021-08-25T11:26:49.746888Z"
        },
        "id": "YsxrAlvFG8SZ"
      },
      "source": [
        "sentence = \"este é um problema que temos que resolver.\"\n",
        "ground_truth = \"this is a problem we have to solve .\"\n",
        "\n",
        "translated_text, translated_tokens, attention_weights = translator(\n",
        "    tf.constant(sentence))\n",
        "print_translation(sentence, translated_text, ground_truth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:26:49.752680Z",
          "iopub.status.busy": "2021-08-25T11:26:49.751869Z",
          "iopub.status.idle": "2021-08-25T11:26:50.796373Z",
          "shell.execute_reply": "2021-08-25T11:26:50.795848Z"
        },
        "id": "7EH5y_aqI4t1"
      },
      "source": [
        "sentence = \"os meus vizinhos ouviram sobre esta ideia.\"\n",
        "ground_truth = \"and my neighboring homes heard about this idea .\"\n",
        "\n",
        "translated_text, translated_tokens, attention_weights = translator(\n",
        "    tf.constant(sentence))\n",
        "print_translation(sentence, translated_text, ground_truth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:26:50.802248Z",
          "iopub.status.busy": "2021-08-25T11:26:50.801254Z",
          "iopub.status.idle": "2021-08-25T11:26:52.887129Z",
          "shell.execute_reply": "2021-08-25T11:26:52.887510Z"
        },
        "id": "J-hVCTSUMlkb"
      },
      "source": [
        "sentence = \"vou então muito rapidamente partilhar convosco algumas histórias de algumas coisas mágicas que aconteceram.\"\n",
        "ground_truth = \"so i \\'ll just share with you some stories very quickly of some magical things that have happened .\"\n",
        "\n",
        "translated_text, translated_tokens, attention_weights = translator(\n",
        "    tf.constant(sentence))\n",
        "print_translation(sentence, translated_text, ground_truth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3EQiFUC--Ds"
      },
      "source": [
        "## Vẽ đồ thị sự chú ý\n",
        "\n",
        "Lớp `Translator` trả về một cuốn từ điển của các bản đồ chú ý bản đồ mà bạn có thể sử dụng để hình dung làm việc nội bộ của mô hình:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHV2pdXHGz-0"
      },
      "source": [
        "The `Translator` class returns a dictionary of attention maps you can use to visualize the internal working of the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:26:52.893477Z",
          "iopub.status.busy": "2021-08-25T11:26:52.892511Z",
          "iopub.status.idle": "2021-08-25T11:26:54.127531Z",
          "shell.execute_reply": "2021-08-25T11:26:54.126816Z"
        },
        "id": "t-kFyiOLH0xg"
      },
      "source": [
        "sentence = \"este é o primeiro livro que eu fiz.\"\n",
        "ground_truth = \"this is the first book i've ever done.\"\n",
        "\n",
        "translated_text, translated_tokens, attention_weights = translator(\n",
        "    tf.constant(sentence))\n",
        "print_translation(sentence, translated_text, ground_truth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:26:54.134557Z",
          "iopub.status.busy": "2021-08-25T11:26:54.133870Z",
          "iopub.status.idle": "2021-08-25T11:26:54.136635Z",
          "shell.execute_reply": "2021-08-25T11:26:54.136121Z"
        },
        "id": "CcI4DxAK5EHY"
      },
      "source": [
        "def plot_attention_head(in_tokens, translated_tokens, attention):\n",
        "  # The plot is of the attention when a token was generated.\n",
        "  # The model didn't generate `<START>` in the output. Skip it.\n",
        "  translated_tokens = translated_tokens[1:]\n",
        "\n",
        "  ax = plt.gca()\n",
        "  ax.matshow(attention)\n",
        "  ax.set_xticks(range(len(in_tokens)))\n",
        "  ax.set_yticks(range(len(translated_tokens)))\n",
        "\n",
        "  labels = [label.decode('utf-8') for label in in_tokens.numpy()]\n",
        "  ax.set_xticklabels(\n",
        "      labels, rotation=90)\n",
        "\n",
        "  labels = [label.decode('utf-8') for label in translated_tokens.numpy()]\n",
        "  ax.set_yticklabels(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:26:54.141817Z",
          "iopub.status.busy": "2021-08-25T11:26:54.141127Z",
          "iopub.status.idle": "2021-08-25T11:26:54.146088Z",
          "shell.execute_reply": "2021-08-25T11:26:54.145643Z"
        },
        "id": "_KY4c2cryuxY"
      },
      "source": [
        "head = 0\n",
        "# shape: (batch=1, num_heads, seq_len_q, seq_len_k)\n",
        "attention_heads = tf.squeeze(\n",
        "  attention_weights['decoder_layer4_block2'], 0)\n",
        "attention = attention_heads[head]\n",
        "attention.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:26:54.151683Z",
          "iopub.status.busy": "2021-08-25T11:26:54.150802Z",
          "iopub.status.idle": "2021-08-25T11:26:54.172132Z",
          "shell.execute_reply": "2021-08-25T11:26:54.171647Z"
        },
        "id": "XdxmakWE6Om3"
      },
      "source": [
        "in_tokens = tf.convert_to_tensor([sentence])\n",
        "in_tokens = tokenizers.pt.tokenize(in_tokens).to_tensor()\n",
        "in_tokens = tokenizers.pt.lookup(in_tokens)[0]\n",
        "in_tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:26:54.177776Z",
          "iopub.status.busy": "2021-08-25T11:26:54.177001Z",
          "iopub.status.idle": "2021-08-25T11:26:54.180999Z",
          "shell.execute_reply": "2021-08-25T11:26:54.180338Z"
        },
        "id": "hVdPSfecmrpj"
      },
      "source": [
        "translated_tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:26:54.198844Z",
          "iopub.status.busy": "2021-08-25T11:26:54.185163Z",
          "iopub.status.idle": "2021-08-25T11:26:54.359135Z",
          "shell.execute_reply": "2021-08-25T11:26:54.358581Z"
        },
        "id": "XtzyKCFamm4N"
      },
      "source": [
        "plot_attention_head(in_tokens, translated_tokens, attention)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:26:54.366308Z",
          "iopub.status.busy": "2021-08-25T11:26:54.365470Z",
          "iopub.status.idle": "2021-08-25T11:26:54.367925Z",
          "shell.execute_reply": "2021-08-25T11:26:54.368307Z"
        },
        "id": "MBliB-PCzNK3"
      },
      "source": [
        "def plot_attention_weights(sentence, translated_tokens, attention_heads):\n",
        "  in_tokens = tf.convert_to_tensor([sentence])\n",
        "  in_tokens = tokenizers.pt.tokenize(in_tokens).to_tensor()\n",
        "  in_tokens = tokenizers.pt.lookup(in_tokens)[0]\n",
        "  in_tokens\n",
        "\n",
        "  fig = plt.figure(figsize=(16, 8))\n",
        "\n",
        "  for h, head in enumerate(attention_heads):\n",
        "    ax = fig.add_subplot(2, 4, h+1)\n",
        "\n",
        "    plot_attention_head(in_tokens, translated_tokens, head)\n",
        "\n",
        "    ax.set_xlabel(f'Head {h+1}')\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:26:54.373282Z",
          "iopub.status.busy": "2021-08-25T11:26:54.372365Z",
          "iopub.status.idle": "2021-08-25T11:26:55.730840Z",
          "shell.execute_reply": "2021-08-25T11:26:55.730089Z"
        },
        "id": "pyRQi7944wru"
      },
      "source": [
        "plot_attention_weights(sentence, translated_tokens,\n",
        "                       attention_weights['decoder_layer4_block2'][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZJirKUtikTt"
      },
      "source": [
        "Mô hình không ổn đối với các từ không quen thuộc. Cả `\"triceratops\"` hoặc `\"encyclopedia\"` đều không có trong tập dữ liệu đầu vào và mô hình gần như học cách chuyển ngữ chúng, ngay cả khi không có từ vựng được chia sẻ:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:26:55.737646Z",
          "iopub.status.busy": "2021-08-25T11:26:55.736545Z",
          "iopub.status.idle": "2021-08-25T11:27:00.057158Z",
          "shell.execute_reply": "2021-08-25T11:27:00.057565Z"
        },
        "id": "9cxysY7uh3jg"
      },
      "source": [
        "sentence = \"Eu li sobre triceratops na enciclopédia.\"\n",
        "ground_truth = \"I read about triceratops in the encyclopedia.\"\n",
        "\n",
        "translated_text, translated_tokens, attention_weights = translator(\n",
        "    tf.constant(sentence))\n",
        "print_translation(sentence, translated_text, ground_truth)\n",
        "\n",
        "plot_attention_weights(sentence, translated_tokens,\n",
        "                       attention_weights['decoder_layer4_block2'][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOyiOetL2l60"
      },
      "source": [
        "## Xuất\n",
        "\n",
        "Đó là mô hình suy luận đang làm việc, vì vậy tiếp theo bạn sẽ xuất nó như là một `tf.saved_model`.\n",
        "\n",
        "Để làm điều đó, gói nó trong một lớp con `tf.Module`, lần này với một `tf.function` trên phương thức `__call__`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:27:00.064287Z",
          "iopub.status.busy": "2021-08-25T11:27:00.063376Z",
          "iopub.status.idle": "2021-08-25T11:27:00.065533Z",
          "shell.execute_reply": "2021-08-25T11:27:00.065954Z"
        },
        "id": "GRmzkibLusQi"
      },
      "source": [
        "class ExportTranslator(tf.Module):\n",
        "  def __init__(self, translator):\n",
        "    self.translator = translator\n",
        "\n",
        "  @tf.function(input_signature=[tf.TensorSpec(shape=[], dtype=tf.string)])\n",
        "  def __call__(self, sentence):\n",
        "    (result, \n",
        "     tokens,\n",
        "     attention_weights) = self.translator(sentence, max_length=100)\n",
        "    \n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9f_pmEA4kql"
      },
      "source": [
        "Ở `tf.function` phía trên chỉ có câu đầu ra được trả về. Nhờ có sự [thực thi không nghiêm ngặt](https://tensorflow.org/guide/intro_to_graphs) trong `tf.function` bất kỳ giá trị không cần thiết không bao giờ tính toán."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:27:00.070719Z",
          "iopub.status.busy": "2021-08-25T11:27:00.069827Z",
          "iopub.status.idle": "2021-08-25T11:27:00.072089Z",
          "shell.execute_reply": "2021-08-25T11:27:00.072451Z"
        },
        "id": "EfomoJDP2n5n"
      },
      "source": [
        "translator = ExportTranslator(translator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUfoCWPS9LuB"
      },
      "source": [
        "Since the model is decoding the predictions using `tf.argmax` the predictions are deterministic. The original model and one reloaded from its `SavedModel` should give identical predictions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:27:00.077530Z",
          "iopub.status.busy": "2021-08-25T11:27:00.076624Z",
          "iopub.status.idle": "2021-08-25T11:27:05.721117Z",
          "shell.execute_reply": "2021-08-25T11:27:05.721553Z"
        },
        "id": "hAlqyycz3IYL"
      },
      "source": [
        "translator(\"este é o primeiro livro que eu fiz.\").numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:27:05.792063Z",
          "iopub.status.busy": "2021-08-25T11:27:05.755806Z",
          "iopub.status.idle": "2021-08-25T11:27:30.775322Z",
          "shell.execute_reply": "2021-08-25T11:27:30.781286Z"
        },
        "id": "ar3LO-Vuvlnv"
      },
      "source": [
        "tf.saved_model.save(translator, export_dir='translator')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:27:30.789538Z",
          "iopub.status.busy": "2021-08-25T11:27:30.788802Z",
          "iopub.status.idle": "2021-08-25T11:27:40.495624Z",
          "shell.execute_reply": "2021-08-25T11:27:40.495075Z"
        },
        "id": "8WUflwyT1SEF"
      },
      "source": [
        "reloaded = tf.saved_model.load('translator')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-25T11:27:40.503141Z",
          "iopub.status.busy": "2021-08-25T11:27:40.500358Z",
          "iopub.status.idle": "2021-08-25T11:27:43.205255Z",
          "shell.execute_reply": "2021-08-25T11:27:43.204752Z"
        },
        "id": "-sBTBWwR1XMr"
      },
      "source": [
        "reloaded(\"este é o primeiro livro que eu fiz.\").numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqQ1fIsLwkGE"
      },
      "source": [
        "## Tóm tắt\n",
        "\n",
        "Trong hướng dẫn này, bạn đã học về mã hóa vị trí, sự chú ý nhiều phía, tầm quan trọng của mặt nạ và cách tạo một transformer.\n",
        "\n",
        "Hãy thử sử dụng một tập dữ liệu khác để huấn luyện transformer. Bạn cũng có thể tạo transformer cơ sở hoặc transformer XL bằng cách thay đổi các siêu tham số ở trên. Bạn cũng có thể sử dụng các lớp định nghĩa ở đây để tạo ra [Bert](https://arxiv.org/abs/1810.04805) và huấn luyện các mô hình hiện đại nhất. Hơn nữa, bạn có thể triển khai tìm kiếm beam để có được những dự đoán tốt hơn."
      ]
    }
  ]
}